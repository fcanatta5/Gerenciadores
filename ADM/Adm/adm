#!/bin/sh
# adm — POSIX package manager (repo local) — versão final corrigida
#
# Layout do repo:
# /var/src/adm/packages/<categoria>/<programa>/
#   build version checksums depends sources patch/ files/ hooks/ queue-status
#
# build do pacote é simples e recebe DESTDIR em $1.
# adm faz: deps, download paralelo, cache, checksum, extract, patch, overlay files/, package, install transacional, DB, logs.
#
# POSIX: sem bashismos, sem cp -a, sem tar GNU flags, sem tar -J obrigatório.
#
set -eu

###############################################################################
# Config
###############################################################################
ADM_ROOT=${ADM_ROOT:-/var/src/adm}
REPO_DIR=${REPO_DIR:-"$ADM_ROOT/packages"}

WORK_DIR=${WORK_DIR:-/var/tmp/adm/work}
SRC_CACHE=${SRC_CACHE:-/var/cache/adm/sources}
BIN_CACHE=${BIN_CACHE:-/var/cache/adm/bins}

DB_DIR=${DB_DIR:-/var/lib/adm}
INST_DIR=$DB_DIR/installed
INDEX_CACHE=$DB_DIR/index.tsv
LOCK_DIR=$DB_DIR/locks
STATE_DIR=$DB_DIR/state

LOG_DIR=${LOG_DIR:-/var/log/adm}
PREFIX=${PREFIX:-/usr/local}
UMASK=${UMASK:-022}

DRYRUN=0
SKIP_SUMS=0
FORCE=0
NO_COLOR=0

DL_JOBS=${DL_JOBS:-4}
BUILD_PARALLEL=${BUILD_PARALLEL:-1}

umask "$UMASK"

###############################################################################
# UI
###############################################################################
C_RESET=; C_BOLD=; C_DIM=; C_RED=; C_GRN=; C_YEL=; C_CYN=
init_colors() {
  if [ -t 1 ] && [ "${NO_COLOR}" -eq 0 ]; then
    C_RESET=$(printf '\033[0m')
    C_BOLD=$(printf '\033[1m')
    C_DIM=$(printf '\033[2m')
    C_RED=$(printf '\033[31m')
    C_GRN=$(printf '\033[32m')
    C_YEL=$(printf '\033[33m')
    C_CYN=$(printf '\033[36m')
  fi
}
say()  { printf '%s\n' "$*"; }
info() { say "${C_CYN}[INFO]${C_RESET} $*"; }
ok()   { say "${C_GRN}[OK]${C_RESET}   $*"; }
warn() { say "${C_YEL}[WARN]${C_RESET} $*"; }
err()  { say "${C_RED}[ERRO]${C_RESET} $*" >&2; }
die()  { err "$*"; exit 1; }

run() {
  if [ "$DRYRUN" -eq 1 ]; then
    say "${C_DIM}DRY-RUN:${C_RESET} $*"
    return 0
  fi
  sh -c "$*"
}

need_cmd() { command -v "$1" >/dev/null 2>&1 || die "Comando ausente: $1"; }
require_root() { [ "$(id -u)" -eq 0 ] || die "Este comando precisa de root."; }

ensure_dirs() {
  run "mkdir -p '$WORK_DIR' '$SRC_CACHE' '$BIN_CACHE' '$DB_DIR' '$INST_DIR' '$LOCK_DIR' '$STATE_DIR' '$LOG_DIR'"
}

ts() { date '+%Y-%m-%d %H:%M:%S'; }
log_path_for() { printf '%s/%s-%s.log\n' "$LOG_DIR" "$1" "$(date '+%Y%m%d-%H%M%S')"; }
sanitize_name() { printf '%s' "$1" | sed 's/[^A-Za-z0-9._+-]/_/g'; }

###############################################################################
# Locks (POSIX lockdir)
###############################################################################
lock_acquire() {
  ensure_dirs
  name=$(sanitize_name "$1")
  tout=${2:-0}
  l="$LOCK_DIR/$name.lock"

  start=$(date +%s 2>/dev/null || echo 0)

  while :; do
    if mkdir "$l" 2>/dev/null; then
      if [ "$DRYRUN" -eq 0 ]; then
        printf '%s\n' "$$" >"$l/pid" 2>/dev/null || true
        printf '%s\n' "$(ts)" >"$l/time" 2>/dev/null || true
      fi
      return 0
    fi
    if [ "$tout" -gt 0 ] && [ "$start" -ne 0 ]; then
      now=$(date +%s 2>/dev/null || echo 0)
      if [ "$now" -ne 0 ] && [ $((now - start)) -ge "$tout" ]; then
        die "timeout aguardando lock: $name"
      fi
    fi
    sleep 1
  done
}

lock_release() {
  name=$(sanitize_name "$1")
  l="$LOCK_DIR/$name.lock"
  if [ "$DRYRUN" -eq 0 ]; then
    rm -f "$l/pid" "$l/time" 2>/dev/null || true
    rmdir "$l" 2>/dev/null || true
  else
    say "${C_DIM}DRY-RUN:${C_RESET} release lock $name"
  fi
}

with_lock() {
  lk="$1"; tout="$2"; shift 2
  lock_acquire "$lk" "$tout"
  trap "lock_release '$lk'" INT TERM EXIT
  "$@"
  trap - INT TERM EXIT
  lock_release "$lk"
}

###############################################################################
# Repo index
###############################################################################
build_index_inner() {
  ensure_dirs
  info "Indexando: ${C_BOLD}$REPO_DIR${C_RESET}"
  tmp="$STATE_DIR/index.$$.tmp"
  if [ "$DRYRUN" -eq 0 ]; then
    find "$REPO_DIR" -mindepth 2 -maxdepth 2 -type d 2>/dev/null \
      | while IFS= read -r d; do
          n=$(basename "$d")
          c=$(basename "$(dirname "$d")")
          printf '%s\t%s\t%s\n' "$n" "$c" "$d"
        done | sort -u >"$tmp"
    mv "$tmp" "$INDEX_CACHE"
  else
    say "${C_DIM}DRY-RUN:${C_RESET} find '$REPO_DIR' ... > '$INDEX_CACHE'"
  fi
  ok "Index pronto: $INDEX_CACHE"
}
build_index() { with_lock "repo.index" 600 build_index_inner; }

resolve_pkg_path() {
  [ -f "$INDEX_CACHE" ] || build_index
  awk -F'\t' -v p="$1" '$1==p{print $3; exit}' "$INDEX_CACHE"
}
resolve_pkg_cat() {
  [ -f "$INDEX_CACHE" ] || build_index
  awk -F'\t' -v p="$1" '$1==p{print $2; exit}' "$INDEX_CACHE"
}
resolve_pkg_ambiguous_count() {
  [ -f "$INDEX_CACHE" ] || build_index
  awk -F'\t' -v p="$1" '$1==p{c++} END{print c+0}' "$INDEX_CACHE"
}
resolve_pkg_ambiguous_list() {
  [ -f "$INDEX_CACHE" ] || build_index
  awk -F'\t' -v p="$1" '$1==p{print $2 "\t" $3}' "$INDEX_CACHE"
}

###############################################################################
# Installed DB
###############################################################################
is_installed() { [ -d "$INST_DIR/$1" ]; }
installed_version() {
  [ -f "$INST_DIR/$1/meta" ] || return 1
  awk -F= '$1=="version"{print $2; exit}' "$INST_DIR/$1/meta"
}
installed_auto() {
  [ -f "$INST_DIR/$1/meta" ] || return 1
  awk -F= '$1=="auto"{print $2; exit}' "$INST_DIR/$1/meta"
}

###############################################################################
# Recipe I/O
###############################################################################
read_version() {
  [ -f "$1/version" ] || die "version ausente: $1"
  sed -n '1p' "$1/version" | tr -d '\r\n'
}
list_depends() {
  if [ -f "$1/depends" ]; then
    sed 's/#.*$//' "$1/depends" | awk 'NF{print $1}'
  fi
}

# sources: 1 URL por linha
# - remove linhas vazias e comentários de linha inteira
# - remove comentários inline do tipo: "URL  # texto"
# - NÃO remove fragmentos #branch/#commit (sem espaço antes do #)
list_sources_raw_lines() {
  if [ -f "$1/sources" ]; then
    sed 's/\r$//' "$1/sources" \
      | sed 's/[[:space:]]*$//' \
      | sed '/^[[:space:]]*#/d; /^$/d' \
      | sed 's/[[:space:]][[:space:]]*#.*$//'
  fi
}

###############################################################################
# Hooks + queue-status
###############################################################################
run_queue_status() {
  qs="$1/queue-status"
  ev="$2"
  if [ -f "$qs" ] && [ -x "$qs" ]; then
    info "queue-status: ${C_BOLD}$ev${C_RESET}"
    run "PKG_EVENT='$ev' '$qs'"
  fi
}
run_hook() {
  h="$1/hooks/$2"
  if [ -f "$h" ] && [ -x "$h" ]; then
    info "hook: ${C_BOLD}$2${C_RESET}"
    run "PKG_HOOK='$2' '$h'"
  fi
}

###############################################################################
# Checksums
###############################################################################
hash_kind_from_hash() { case "${#1}" in 64) echo sha256 ;; 32) echo md5 ;; *) echo "" ;; esac; }
sum_cmd_for() {
  case "$1" in
    sha256) command -v sha256sum >/dev/null 2>&1 && echo sha256sum || echo "" ;;
    md5)    command -v md5sum    >/dev/null 2>&1 && echo md5sum    || echo "" ;;
    *)      echo "" ;;
  esac
}
checksum_expected_for_file() { awk -v f="$2" 'NF>=2{if($2==f){print $1; exit}}' "$1"; }
checksums_has_file() { awk -v f="$2" 'NF>=2{if($2==f){found=1}} END{exit found?0:1}' "$1"; }

verify_one_checksum() {
  [ "$SKIP_SUMS" -eq 1 ] && return 0
  csum="$1"; dir="$2"; f="$3"
  [ -f "$csum" ] || { warn "checksums ausente; pulando."; return 0; }

  exp=$(checksum_expected_for_file "$csum" "$f" | tr -d '\r')
  [ -n "$exp" ] || die "checksums não contém entrada para: $f"
  kind=$(hash_kind_from_hash "$exp"); [ -n "$kind" ] || die "hash inválido em checksums para $f"
  cmd=$(sum_cmd_for "$kind"); [ -n "$cmd" ] || die "Faltando ferramenta: $kind (precisa de ${kind}sum)."

  got=$((cd "$dir" && "$cmd" "$f") 2>/dev/null | awk '{print $1}')
  [ "$got" = "$exp" ]
}

###############################################################################
# Download + sources parsing (#branch= / #commit=)
###############################################################################
dl_tool() {
  if command -v curl >/dev/null 2>&1; then echo curl
  elif command -v wget >/dev/null 2>&1; then echo wget
  else echo ""
  fi
}
download_http_one() {
  tool=$(dl_tool); [ -n "$tool" ] || die "Precisa de curl ou wget."
  if [ "$tool" = curl ]; then
    run "curl -L --fail --retry 3 --retry-delay 1 --progress-bar -o '$2' '$1'"
  else
    run "wget --tries=3 --timeout=30 --progress=bar:force:noscroll -O '$2' '$1'"
  fi
}

url_strip_fragment() { printf '%s' "$1" | awk -F'#' '{print $1}'; }
url_fragment() { printf '%s' "$1" | awk -F'#' 'NF>=2{print $2}'; }
url_basename() { printf '%s' "$1" | sed 's/[?#].*$//' | awk -F/ '{print $NF}'; }
frag_get() { printf '%s' "$1" | tr '&' '\n' | tr ' ' '\n' | awk -F= -v k="$2" '$1==k{print $2; exit}'; }

hash_key() {
  if command -v sha256sum >/dev/null 2>&1; then printf '%s' "$1" | sha256sum | awk '{print $1}'
  else printf '%s' "$1" | md5sum | awk '{print $1}'
  fi
}

cp_tree_posix() {
  # Copia diretório preservando permissões/tempos onde possível (POSIX)
  # $1=srcdir $2=dstdir (já existe)
  # usa tar pipeline (portável) para preservar symlinks, perms, etc.
  src="$1"; dst="$2"
  run "(cd '$src' && tar -cf - .) | (cd '$dst' && tar -xf -)"
}

download_git_cached() {
  need_cmd git
  url="$1"; cachedir="$2"; branch="${3:-}"; commit="${4:-}"

  case "$url" in git+*) url=$(printf '%s' "$url" | sed 's/^git+//') ;; esac

  k=$(hash_key "$url")
  d="$cachedir/git-$k"

  if [ -d "$d/.git" ]; then
    info "git cache hit: ${C_BOLD}$url${C_RESET}"
    run "git -C '$d' fetch --all --prune"
  else
    info "git clone: ${C_BOLD}$url${C_RESET}"
    run "rm -rf '$d'"
    run "git clone --recursive '$url' '$d'"
  fi

  if [ -n "$branch" ]; then
    run "git -C '$d' checkout -f '$branch'"
    run "git -C '$d' pull --ff-only || true"
  fi

  if [ -n "$commit" ]; then
    run "git -C '$d' checkout -f '$commit'"
    if [ "$DRYRUN" -eq 0 ]; then
      head=$(git -C "$d" rev-parse HEAD 2>/dev/null || echo "")
      [ "$head" = "$commit" ] || die "git verify falhou: HEAD=$head esperado=$commit"
    fi
  fi

  echo "$d"
}

copy_cached_or_download_one() {
  pkg="$1"; pkgpath="$2"; raw="$3"; outdir="$4"
  csum="$pkgpath/checksums"
  mkdir -p "$outdir" "$SRC_CACHE/$pkg"

  base=$(url_strip_fragment "$raw")
  frag=$(url_fragment "$raw")
  branch=$(frag_get "$frag" "branch" || true)
  commit=$(frag_get "$frag" "commit" || true)

  case "$base" in
    http://*|https://*|ftp://*)
      f=$(url_basename "$base"); [ -n "$f" ] || die "URL inválida: $base"

      if [ -f "$csum" ] && [ "$SKIP_SUMS" -eq 0 ]; then
        checksums_has_file "$csum" "$f" || die "checksums não contém $f (obrigatório quando checksums existe)"
      fi

      cf="$SRC_CACHE/$pkg/$f"
      of="$outdir/$f"

      if [ -f "$cf" ]; then
        info "cache source: $pkg/$f"
        run "cp -f '$cf' '$of'"
        if verify_one_checksum "$csum" "$outdir" "$f"; then
          ok "checksum OK (cache): $f"
          return 0
        fi
        warn "checksum falhou (cache): $f; rebaixando"
        run "rm -f '$cf' '$of'"
      fi

      info "download: ${C_BOLD}$f${C_RESET}"
      download_http_one "$base" "$of"

      if verify_one_checksum "$csum" "$outdir" "$f"; then
        ok "checksum OK: $f"
        run "cp -f '$of' '$cf'"
      else
        run "rm -f '$of' '$cf'"
        die "checksum falhou após download: $f"
      fi
      ;;
    git:*|ssh://*|git@*:*|*".git"|git+*)
      d=$(download_git_cached "$base" "$SRC_CACHE/$pkg" "$branch" "$commit")
      k=$(basename "$d")
      run "rm -rf '$outdir/$k'"
      run "mkdir -p '$outdir/$k'"
      cp_tree_posix "$d" "$outdir/$k"
      ;;
    *)
      die "source não suportada: $base"
      ;;
  esac
}

download_sources_parallel() {
  pkg="$1"; pkgpath="$2"; outdir="$3"
  ensure_dirs
  srcs=$(list_sources_raw_lines "$pkgpath" || true)
  [ -n "${srcs:-}" ] || { info "Sem sources."; return 0; }

  if [ "$DRYRUN" -eq 1 ]; then
    say "${C_DIM}DRY-RUN:${C_RESET} downloads:"
    printf '%s\n' "$srcs" | sed 's/^/  - /'
    return 0
  fi

  tmp="$STATE_DIR/srcs.$pkg.$$"
  printf '%s\n' "$srcs" >"$tmp"

  pids=""; running=0
  while IFS= read -r raw; do
    (
      set -eu
      copy_cached_or_download_one "$pkg" "$pkgpath" "$raw" "$outdir"
    ) &
    pid=$!
    pids="$pids $pid"
    running=$((running + 1))

    if [ "$running" -ge "$DL_JOBS" ]; then
      first=$(printf '%s\n' "$pids" | awk '{print $1}')
      wait "$first" || { rm -f "$tmp"; die "Falha em download paralelo."; }
      pids=$(printf '%s\n' "$pids" | awk '{$1=""; sub(/^ /,""); print}')
      running=$((running - 1))
    fi
  done <"$tmp"
  rm -f "$tmp"

  for pid in $pids; do
    wait "$pid" || die "Falha em download paralelo."
  done

  # Se checksums existe e não foi skip: garantir que TODOS os arquivos listados existem no outdir
  if [ -f "$pkgpath/checksums" ] && [ "$SKIP_SUMS" -eq 0 ]; then
    awk 'NF>=2{print $2}' "$pkgpath/checksums" | while IFS= read -r f; do
      [ -n "$f" ] || continue
      [ -f "$outdir/$f" ] || die "checksums cita '$f' mas arquivo não foi baixado para $outdir"
    done
  fi
}

###############################################################################
# Deps topo + ciclo
###############################################################################
deps_toposort() {
  marks="$STATE_DIR/marks.$$.tmp"
  out="$STATE_DIR/order.$$.tmp"
  : >"$marks"; : >"$out"

  dfs() {
    n="$1"
    if grep "^perm $n\$" "$marks" >/dev/null 2>&1; then return 0; fi
    if grep "^temp $n\$" "$marks" >/dev/null 2>&1; then die "Ciclo em dependências envolvendo: $n"; fi
    echo "temp $n" >>"$marks"

    p=$(resolve_pkg_path "$n"); [ -n "$p" ] || die "Dependência não encontrada no repo: $n"
    for d in $(list_depends "$p"); do dfs "$d"; done

    grep -v "^temp $n\$" "$marks" >"$marks.$$" && mv "$marks.$$" "$marks"
    echo "perm $n" >>"$marks"
    echo "$n" >>"$out"
  }

  dfs "$1"
  cat "$out"
  rm -f "$marks" "$out"
}

###############################################################################
# Archive extract helpers (busybox-safe)
###############################################################################
extract_archive_to() {
  a="$1"; d="$2"
  case "$a" in
    *.tar)       run "tar -xf '$a' -C '$d'" ;;
    *.tar.gz|*.tgz)
      command -v gzip >/dev/null 2>&1 || die "gzip ausente para extrair: $a"
      run "gzip -dc '$a' | tar -xf - -C '$d'"
      ;;
    *.tar.bz2|*.tbz2)
      command -v bzip2 >/dev/null 2>&1 || die "bzip2 ausente para extrair: $a"
      run "bzip2 -dc '$a' | tar -xf - -C '$d'"
      ;;
    *.tar.xz|*.txz)
      command -v xz >/dev/null 2>&1 || die "xz ausente para extrair: $a"
      run "xz -dc '$a' | tar -xf - -C '$d'"
      ;;
    *) die "arquivo não suportado: $a" ;;
  esac
}

###############################################################################
# Extract + patch + overlay
###############################################################################
extract_sources() {
	# Extrai sources baixados em $dldir para $srcdir.
	# Evolução: extrai MULTIPLOS tarballs (em ordem determinística).
	# Retorna (echo) o SRCROOT a ser usado pelo build:
	# - se git snapshot existir: $srcdir/src
	# - senão: primeiro diretório top-level criado pela extração do primeiro tarball
	#          (ou $srcdir se não houver diretório top-level)

	dldir=$1
	srcdir=$2

	# 1) Se existir snapshot git (git-*), mantém comportamento atual:
	#    copia snapshot para $srcdir/src e usa isso como SRCROOT.
	gitdir=$(find "$dldir" -mindepth 1 -maxdepth 1 -type d -name 'git-*' 2>/dev/null | head -n1 || true)
	if [ -n "${gitdir:-}" ] && [ -d "$gitdir" ]; then
		rm -rf "$srcdir"
		mkdir -p "$srcdir/src"
		cp_tree_posix "$gitdir" "$srcdir/src"
		echo "$srcdir/src"
		return 0
	fi

	# 2) Tarballs: extrair TODOS em ordem.
	# Limpa o srcdir uma vez, no início.
	rm -rf "$srcdir"
	mkdir -p "$srcdir"

	# Lista determinística de arquivos suportados (ordenada).
	# Compatível com o conjunto de extensões que o adm já suporta via extract_archive_to().
	archives=$(
		# -print0 evita problemas com espaços, mas aqui simplificamos mantendo basename normal;
		# se você tiver nomes com espaços, eu adapto para -print0 + while read -d ''.
		find "$dldir" -mindepth 1 -maxdepth 1 -type f \( \
			-name '*.tar' -o \
			-name '*.tar.gz' -o -name '*.tgz' -o \
			-name '*.tar.bz2' -o -name '*.tbz2' -o \
			-name '*.tar.xz' -o -name '*.txz' \
		\) 2>/dev/null | LC_ALL=C sort
	)

	if [ -z "${archives:-}" ]; then
		die "nenhum tarball suportado encontrado em $dldir"
	fi

	# Para escolher um SRCROOT estável: medimos o estado antes/depois do PRIMEIRO tarball.
	first=1
	srcroot=""

	for a in $archives; do
		# Para o primeiro tarball, capture snapshot do top-level antes.
		if [ "$first" -eq 1 ]; then
			before=$(
				( cd "$srcdir" && find . -mindepth 1 -maxdepth 1 -print ) 2>/dev/null | LC_ALL=C sort
			)
		fi

		info "extraindo $(basename "$a")"
		extract_archive_to "$a" "$srcdir"

		# Após extrair o primeiro tarball, determine o SRCROOT
		if [ "$first" -eq 1 ]; then
			after=$(
				( cd "$srcdir" && find . -mindepth 1 -maxdepth 1 -print ) 2>/dev/null | LC_ALL=C sort
			)

			# Diferencial: entradas novas no top-level.
			new_top=$(
				# comm requer inputs ordenados; usamos sort acima.
				comm -13 \
					<(printf '%s\n' "$before") \
					<(printf '%s\n' "$after") \
				2>/dev/null | head -n1 || true
			)

			# Normaliza "./foo" -> "foo"
			new_top=${new_top#./}

			if [ -n "${new_top:-}" ] && [ -d "$srcdir/$new_top" ]; then
				srcroot="$srcdir/$new_top"
			else
				# Se não houve diretório top-level novo, usa o próprio srcdir.
				srcroot="$srcdir"
			fi

			first=0
		fi
	done

	# Se por algum motivo não definimos srcroot, fallback.
	if [ -z "${srcroot:-}" ]; then
		srcroot="$srcdir"
	fi

	echo "$srcroot"
	return 0
}

apply_patches_dir() {
  pkgpath="$1"; srcroot="$2"
  [ -d "$pkgpath/patch" ] || return 0
  command -v patch >/dev/null 2>&1 || { warn "patch ausente; ignorando patch/."; return 0; }
  for p in "$pkgpath"/patch/*.patch "$pkgpath"/patch/*.diff; do
    [ -f "$p" ] || continue
    info "patch: $(basename "$p")"
    run "patch -d '$srcroot' -p1 < '$p'"
  done
}

overlay_files_dir() {
  pkgpath="$1"; destdir="$2"
  [ -d "$pkgpath/files" ] || return 0
  if [ "$DRYRUN" -eq 0 ]; then
    if find "$pkgpath/files" -mindepth 1 -maxdepth 1 >/dev/null 2>&1; then
      info "overlay: files/ -> DESTDIR"
      # POSIX: preserva com tar pipeline
      run "(cd '$pkgpath/files' && tar -cf - .) | (cd '$destdir' && tar -xf -)"
    fi
  else
    say "${C_DIM}DRY-RUN:${C_RESET} overlay files/ -> DESTDIR"
  fi
}

###############################################################################
# Packaging + manifest (tar.xz)
###############################################################################
pkg_filename() {
  arch=$(uname -m 2>/dev/null || echo unknown)
  echo "$BIN_CACHE/$1-$2-$arch.tar.xz"
}

package_destdir() {
  dest="$1"; pf="$2"; lf="$3"
  info "package: ${C_BOLD}$(basename "$pf")${C_RESET}"
  command -v xz >/dev/null 2>&1 || die "xz é obrigatório para empacotar tar.xz"
  if [ "$DRYRUN" -eq 0 ]; then
    (cd "$dest" && tar -cf - .) | xz -T0 -9e >"$pf" 2>>"$lf"
  else
    say "${C_DIM}DRY-RUN:${C_RESET} tar|xz -> '$pf'"
  fi
}

manifest_from_tar_xz() {
  # lista entries do tar.xz sem depender de tar -J
  command -v xz >/dev/null 2>&1 || die "xz ausente para listar: $1"
  xz -dc "$1" | tar -tf - 2>/dev/null \
    | sed 's|^\./||' \
    | awk 'NF{print $0}' \
    | sort -u
}

validate_manifest_entries() {
  # $1=manifest_file
  mf="$1"
  bad=0
  while IFS= read -r p; do
    [ -n "$p" ] || continue
    case "$p" in
      /*) bad=1 ;;
      *".."*) bad=1 ;;
      "") bad=1 ;;
    esac
    # bloqueia controle óbvio
    case "$p" in
      *$'\n'*|*$'\r'*|*$'\t'*) bad=1 ;;
    esac
    if [ "$bad" -eq 1 ]; then
      err "Entrada de pacote inválida/perigosa: '$p'"
      return 1
    fi
  done <"$mf"
  return 0
}

###############################################################################
# Ownership helpers
###############################################################################
file_owned_by_other() {
  f="$1"; self="$2"
  for d in "$INST_DIR"/*; do
    [ -d "$d" ] || continue
    p=$(basename "$d")
    [ "$p" = "$self" ] && continue
    mf="$d/manifest"
    [ -f "$mf" ] || continue
    grep -Fx "$f" "$mf" >/dev/null 2>&1 && return 0
  done
  return 1
}

###############################################################################
# File hashing for verify
###############################################################################
hash_tool_kind() {
  if command -v sha256sum >/dev/null 2>&1; then echo sha256
  elif command -v md5sum >/dev/null 2>&1; then echo md5
  else echo ""
  fi
}

hash_file_kind() {
  kind="$1"; path="$2"
  case "$kind" in
    sha256) sha256sum "$path" | awk '{print $1}' ;;
    md5)    md5sum "$path"    | awk '{print $1}' ;;
    *) echo "" ;;
  esac
}

write_filehashes() {
  pkg="$1"; mf="$2"; out="$3"
  kind=$(hash_tool_kind)
  : >"$out"
  [ -n "$kind" ] || { warn "Sem sha256sum/md5sum; verify ficará superficial."; return 0; }
  printf 'ALG=%s\n' "$kind" >>"$out"

  while IFS= read -r f; do
    [ -n "$f" ] || continue
    case "$f" in *".."*) continue ;; esac
    path="/$f"

    if [ -L "$path" ]; then
      tgt=$(readlink "$path" 2>/dev/null || echo "")
      # grava com separador TAB para não depender de espaços
      printf 'L\t%s\t%s\n' "$tgt" "$f" >>"$out"
      continue
    fi
    if [ -f "$path" ]; then
      h=$(hash_file_kind "$kind" "$path" 2>/dev/null || echo "")
      [ -n "$h" ] || continue
      printf 'F\t%s\t%s\n' "$h" "$f" >>"$out"
    fi
  done <"$mf"
}

###############################################################################
# Build
###############################################################################
build_one_inner() {
  pkg="$1"

  amb=$(resolve_pkg_ambiguous_count "$pkg")
  if [ "$amb" -gt 1 ]; then
    err "Programa ambíguo: $pkg"
    resolve_pkg_ambiguous_list "$pkg" | awk '{printf "  - %s (%s)\n", $2, $1}'
    die "Mantenha nomes únicos por categoria."
  fi

  pkgpath=$(resolve_pkg_path "$pkg"); [ -n "$pkgpath" ] || die "Não encontrado no repo: $pkg"
  ver=$(read_version "$pkgpath")
  catg=$(resolve_pkg_cat "$pkg")
  pf=$(pkg_filename "$pkg" "$ver")

  if [ -f "$pf" ] && [ "$FORCE" -eq 0 ]; then
    ok "bin cache hit: $pf"
    return 0
  fi

  ensure_dirs
  lf=$(log_path_for "$pkg")

  info "build: ${C_BOLD}$pkg${C_RESET} ${C_DIM}($catg)${C_RESET} v${C_BOLD}$ver${C_RESET}"
  info "log:  ${C_BOLD}$lf${C_RESET}"

  b="$WORK_DIR/build/$(sanitize_name "$pkg")-$ver.$$"
  dld="$b/dl"
  srcd="$b/src"
  buildd="$b/build"
  dest="$b/dest"

  run "mkdir -p '$dld' '$srcd' '$buildd' '$dest'"

  export PKG="$pkg" VER="$ver" PKGPATH="$pkgpath"
  export WORK="$b" DL_DIR="$dld" SRC_DIR="$srcd" BUILD_DIR="$buildd" DESTDIR="$dest"
  export PREFIX="$PREFIX" DL_JOBS="$DL_JOBS" LOGFILE="$lf"

  {
    echo "== $(ts) :: build $pkg $ver =="
    echo "PKGPATH=$pkgpath"
    echo "WORK=$b"
    echo "PREFIX=$PREFIX"
    echo "DL_JOBS=$DL_JOBS"
  } >>"$lf"

  run_hook "$pkgpath" "pre-source"; run_queue_status "$pkgpath" "pre-source"
  with_lock "cache.sources.$pkg" 600 download_sources_parallel "$pkg" "$pkgpath" "$dld" >>"$lf" 2>&1
  run_hook "$pkgpath" "post-source"; run_queue_status "$pkgpath" "post-source"

  run_hook "$pkgpath" "pre-extract"; run_queue_status "$pkgpath" "pre-extract"
  srcroot=$(extract_sources "$dld" "$srcd")
  export SRCROOT="$srcroot"
  run_hook "$pkgpath" "post-extract"; run_queue_status "$pkgpath" "post-extract"

  apply_patches_dir "$pkgpath" "$SRCROOT" >>"$lf" 2>&1

  run_hook "$pkgpath" "pre-build"; run_queue_status "$pkgpath" "pre-build"

  [ -f "$pkgpath/build" ] || die "build ausente: $pkgpath/build"
  info "run build: ${C_BOLD}$pkgpath/build${C_RESET}"

  if [ "$DRYRUN" -eq 0 ]; then
    (
      set -eu
      cd "$SRCROOT"
      if [ -x "$PKGPATH/build" ]; then
        "$PKGPATH/build" "$DESTDIR"
      else
        sh "$PKGPATH/build" "$DESTDIR"
      fi
    ) >>"$lf" 2>&1 || die "Build falhou. Veja: $lf"
  else
    say "${C_DIM}DRY-RUN:${C_RESET} (cd '$SRCROOT' && sh '$pkgpath/build' '$DESTDIR')"
  fi

  run_hook "$pkgpath" "post-build"; run_queue_status "$pkgpath" "post-build"

  run_hook "$pkgpath" "pre-install"; run_queue_status "$pkgpath" "pre-install"
  overlay_files_dir "$pkgpath" "$DESTDIR" >>"$lf" 2>&1
  run_hook "$pkgpath" "post-install"; run_queue_status "$pkgpath" "post-install"

  run_hook "$pkgpath" "post-package"; run_queue_status "$pkgpath" "post-package"
  package_destdir "$DESTDIR" "$pf" "$lf"

  ok "build OK: $pkg v$ver"
  ok "bin: $pf"
}
build_one() { with_lock "build.$1" 600 build_one_inner "$1"; }

build_many() {
  [ $# -gt 0 ] || die "Uso: adm build <pkg> [pkg...]"
  if [ "$BUILD_PARALLEL" -le 1 ] || [ "$DRYRUN" -eq 1 ]; then
    for p in "$@"; do build_one "$p"; done
    return 0
  fi

  pids=""; running=0
  for p in "$@"; do
    ( set -eu; build_one "$p" ) &
    pid=$!
    pids="$pids $pid"
    running=$((running + 1))
    if [ "$running" -ge "$BUILD_PARALLEL" ]; then
      first=$(printf '%s\n' "$pids" | awk '{print $1}')
      wait "$first" || die "falha em build paralelo"
      pids=$(printf '%s\n' "$pids" | awk '{$1=""; sub(/^ /,""); print}')
      running=$((running - 1))
    fi
  done
  for pid in $pids; do wait "$pid" || die "falha em build paralelo"; done
}

###############################################################################
# Install transacional (stage + backup/rollback) — POSIX, sem ARG_MAX, rollback completo
###############################################################################
record_installed_db() {
  pkg="$1"; ver="$2"; auto="$3"; pkgpath="$4"; pf="$5"
  idir="$INST_DIR/$pkg"
  mkdir -p "$idir"

  {
    echo "name=$pkg"
    echo "version=$ver"
    echo "category=$(resolve_pkg_cat "$pkg" 2>/dev/null || echo unknown)"
    echo "auto=$auto"
    echo "installed_at=$(ts)"
    echo "bin=$(basename "$pf")"
  } >"$idir/meta"

  if [ -f "$pkgpath/depends" ]; then
    sed 's/#.*$//' "$pkgpath/depends" | awk 'NF{print $1}' >"$idir/depends"
  else
    : >"$idir/depends"
  fi
}

rmdir_from_manifest_reverse() {
  mf="$1"
  awk -F/ 'NF>1{p=""; for(i=1;i<NF;i++){p=p"/"$i; print p}}' "$mf" \
    | sort -u -r | while IFS= read -r d; do
        rmdir "$d" 2>/dev/null || true
      done
}

install_tar_transact() {
  pkg="$1"; tf="$2"; lf="$3"
  [ -f "$tf" ] || die "pacote binário ausente: $tf"
  require_root
  command -v xz >/dev/null 2>&1 || die "xz é obrigatório para instalar tar.xz: $tf"

  if [ "$DRYRUN" -eq 1 ]; then
    say "${C_DIM}DRY-RUN:${C_RESET} install transacional de '$tf' -> /"
    return 0
  fi

  stage="$STATE_DIR/stage.$pkg.$$"
  backup="$STATE_DIR/backup.$pkg.$$.tar"
  existed="$STATE_DIR/existed.$pkg.$$"
  newfiles="$STATE_DIR/newfiles.$pkg.$$"
  touchlist="$STATE_DIR/touch.$pkg.$$"

  mkdir -p "$stage"

  # manifest a partir do tar.xz + validação forte
  manifest_from_tar_xz "$tf" >"$touchlist"
  validate_manifest_entries "$touchlist" || { rm -rf "$stage"; rm -f "$backup" "$existed" "$newfiles" "$touchlist"; die "pacote contém entradas perigosas"; }

  : >"$existed"; : >"$newfiles"
  while IFS= read -r f; do
    [ -n "$f" ] || continue
    if [ -e "/$f" ] || [ -L "/$f" ]; then
      printf '%s\n' "$f" >>"$existed"
    else
      printf '%s\n' "$f" >>"$newfiles"
    fi
  done <"$touchlist"

  # 1) extrai no stage (sem tar -J)
  if ! xz -dc "$tf" | tar -xf - -C "$stage" >>"$lf" 2>&1; then
    rm -rf "$stage" "$backup" "$existed" "$newfiles" "$touchlist"
    die "falha ao extrair pacote no stage"
  fi

  # 2) backup POSIX sem ARG_MAX:
  #    cria com o primeiro arquivo, depois tar -rf para o resto.
  rm -f "$backup"
  if [ -s "$existed" ]; then
    first=$(sed -n '1p' "$existed" || true)
    if [ -n "$first" ]; then
      (cd / && tar -cf "$backup" "$first") >>"$lf" 2>&1 || {
        rm -rf "$stage" "$backup" "$existed" "$newfiles" "$touchlist"
        die "falha criando backup (primeiro arquivo)"
      }
      # resto
      tailfile="$STATE_DIR/existed.tail.$pkg.$$"
      awk 'NR>1{print $0}' "$existed" >"$tailfile"
      while IFS= read -r f; do
        [ -n "$f" ] || continue
        (cd / && tar -rf "$backup" "$f") >>"$lf" 2>&1 || {
          rm -rf "$stage" "$backup" "$existed" "$newfiles" "$touchlist" "$tailfile"
          die "falha anexando ao backup (tar -rf)"
        }
      done <"$tailfile"
      rm -f "$tailfile"
    fi
  fi

  # 3) aplica stage em /
  if (cd "$stage" && tar -cf - .) | (cd / && tar -xf -) >>"$lf" 2>&1; then
    rm -rf "$stage" "$backup" "$existed" "$newfiles" "$touchlist"
    return 0
  fi

  warn "instalação falhou; iniciando rollback"

  # remove novos (arquivos/symlinks). Depois tenta remover dirs criados.
  if [ -s "$newfiles" ]; then
    while IFS= read -r f; do
      [ -n "$f" ] || continue
      rm -f "/$f" 2>/dev/null || true
    done <"$newfiles"
    # remove dirs derivados do manifest
    rmdir_from_manifest_reverse "$newfiles" || true
  fi

  # restaura backup (se houver)
  if [ -f "$backup" ] && [ -s "$existed" ]; then
    (cd / && tar -xf "$backup") >>"$lf" 2>&1 || true
  fi

  # limpar
  rm -rf "$stage" "$backup" "$existed" "$newfiles" "$touchlist"
  die "instalação falhou e foi revertida"
}

remove_files_from_manifest_delta() {
  pkg="$1"; oldmf="$2"; newmf="$3"
  [ "$DRYRUN" -eq 1 ] && { say "${C_DIM}DRY-RUN:${C_RESET} removeria delta antigo"; return 0; }

  awk 'FNR==NR{n[$0]=1; next} !n[$0]{print $0}' "$newmf" "$oldmf" \
    | while IFS= read -r f; do
        [ -n "$f" ] || continue
        file_owned_by_other "$f" "$pkg" && continue
        rm -f "/$f" 2>/dev/null || true
      done

  # limpa dirs do antigo
  awk -F/ 'NF>1{p=""; for(i=1;i<NF;i++){p=p"/"$i; print p}}' "$oldmf" \
    | sort -u -r | while IFS= read -r d; do rmdir "/$d" 2>/dev/null || true; done
}

install_one_inner() {
  pkg="$1"; auto="${2:-0}"
  pkgpath=$(resolve_pkg_path "$pkg"); [ -n "$pkgpath" ] || die "Não encontrado no repo: $pkg"
  ver=$(read_version "$pkgpath")
  pf=$(pkg_filename "$pkg" "$ver")
  lf=$(log_path_for "$pkg")

  info "deps: ${C_BOLD}$pkg${C_RESET}"
  for d in $(deps_toposort "$pkg"); do
    [ "$d" = "$pkg" ] && continue
    if ! is_installed "$d"; then
      with_lock "install.$d" 600 install_one_inner "$d" 1
    fi
  done

  if [ ! -f "$pf" ] || [ "$FORCE" -eq 1 ]; then
    build_one "$pkg"
  fi

  if is_installed "$pkg"; then
    run_hook "$pkgpath" "pre-update"; run_queue_status "$pkgpath" "pre-update"
  fi
  run_hook "$pkgpath" "pre-install"; run_queue_status "$pkgpath" "pre-install"

  oldver=""
  oldmf_tmp="$STATE_DIR/$pkg.oldmf.$$"
  newmf_tmp="$STATE_DIR/$pkg.newmf.$$"

  if is_installed "$pkg"; then
    oldver=$(installed_version "$pkg" 2>/dev/null || true)
    [ -f "$INST_DIR/$pkg/manifest" ] && cp -f "$INST_DIR/$pkg/manifest" "$oldmf_tmp"
  fi

  info "install: ${C_BOLD}$pkg${C_RESET} v${C_BOLD}$ver${C_RESET}"
  install_tar_transact "$pkg" "$pf" "$lf"

  if [ "$DRYRUN" -eq 0 ]; then
    manifest_from_tar_xz "$pf" >"$newmf_tmp"
    validate_manifest_entries "$newmf_tmp" || die "manifest gerado do pacote é inválido"
    idir="$INST_DIR/$pkg"
    mkdir -p "$idir"
    cp -f "$newmf_tmp" "$idir/manifest"
    record_installed_db "$pkg" "$ver" "$auto" "$pkgpath" "$pf"
    write_filehashes "$pkg" "$idir/manifest" "$idir/filehashes"
  fi

  run_hook "$pkgpath" "post-install"; run_queue_status "$pkgpath" "post-install"

  if [ -n "$oldver" ] && [ "$oldver" != "$ver" ]; then
    run_hook "$pkgpath" "post-update"; run_queue_status "$pkgpath" "post-update"
  fi

  if [ -n "$oldver" ] && [ "$oldver" != "$ver" ] && [ -f "$oldmf_tmp" ] && [ -f "$newmf_tmp" ]; then
    info "upgrade: delta seguro $pkg v$oldver -> v$ver"
    remove_files_from_manifest_delta "$pkg" "$oldmf_tmp" "$newmf_tmp"
  fi

  rm -f "$oldmf_tmp" "$newmf_tmp" 2>/dev/null || true
  ok "instalado: $pkg v$ver"
}

# DB lock REAL: segura durante a transação inteira
install_one() { require_root; with_lock "db" 600 with_lock "install.$1" 600 install_one_inner "$1" "${2:-0}"; }

###############################################################################
# Remove + orphans
###############################################################################
remove_one_inner() {
  pkg="$1"
  is_installed "$pkg" || die "Não instalado: $pkg"

  pkgpath=$(resolve_pkg_path "$pkg" 2>/dev/null || true)
  if [ -n "${pkgpath:-}" ]; then
    run_hook "$pkgpath" "pre-remove"; run_queue_status "$pkgpath" "pre-remove"
  fi

  mf="$INST_DIR/$pkg/manifest"
  [ -f "$mf" ] || die "manifest ausente: $mf"
  info "remove: ${C_BOLD}$pkg${C_RESET}"

  if [ "$DRYRUN" -eq 0 ]; then
    awk '{a[NR]=$0} END{for(i=NR;i>=1;i--) print a[i]}' "$mf" \
      | while IFS= read -r f; do
          [ -n "$f" ] || continue
          file_owned_by_other "$f" "$pkg" && continue
          rm -f "/$f" 2>/dev/null || true
        done

    awk -F/ 'NF>1{p=""; for(i=1;i<NF;i++){p=p"/"$i; print p}}' "$mf" \
      | sort -u -r | while IFS= read -r d; do rmdir "/$d" 2>/dev/null || true; done

    rm -rf "$INST_DIR/$pkg"
  else
    say "${C_DIM}DRY-RUN:${C_RESET} removeria arquivos de $pkg"
  fi

  if [ -n "${pkgpath:-}" ]; then
    run_hook "$pkgpath" "post-remove" || true
    run_queue_status "$pkgpath" "post-remove" || true
  fi
  ok "removido: $pkg"
}

remove_one() { require_root; with_lock "db" 600 with_lock "install.$1" 600 remove_one_inner "$1"; }

reverse_deps() {
  target="$1"
  for d in "$INST_DIR"/*; do
    [ -d "$d" ] || continue
    p=$(basename "$d")
    depf="$d/depends"
    [ -f "$depf" ] || continue
    grep -Fx "$target" "$depf" >/dev/null 2>&1 && echo "$p"
  done | sort -u
}

remove_orphans_inner() {
  info "orphans: removendo auto=1 sem reverse-deps"
  changed=1
  while [ "$changed" -eq 1 ]; do
    changed=0
    for d in "$INST_DIR"/*; do
      [ -d "$d" ] || continue
      p=$(basename "$d")
      a=$(installed_auto "$p" 2>/dev/null || echo 0)
      [ "$a" = 1 ] || continue
      r=$(reverse_deps "$p" | awk 'END{print NR+0}')
      if [ "$r" -eq 0 ]; then
        warn "órfão: $p"
        with_lock "install.$p" 600 remove_one_inner "$p"
        changed=1
      fi
    done
  done
  ok "orphans: concluído"
}
remove_orphans() { require_root; with_lock "db" 600 remove_orphans_inner; }

###############################################################################
# Update / Rebuild-all
###############################################################################
repo_update_inner() {
  ensure_dirs
  if [ -d "$ADM_ROOT/.git" ]; then
    need_cmd git
    info "update: git pull em ${C_BOLD}$ADM_ROOT${C_RESET}"
    run "git -C '$ADM_ROOT' pull --ff-only"
    ok "update: OK"
  else
    warn "update: $ADM_ROOT não é git; pulando"
  fi
  build_index_inner
}
repo_update() { with_lock "repo" 600 repo_update_inner; }

rebuild_all_installed_inner() {
  info "rebuild-all: reinstalando todos os instalados"
  for d in "$INST_DIR"/*; do
    [ -d "$d" ] || continue
    p=$(basename "$d")
    a=$(installed_auto "$p" 2>/dev/null || echo 0)
    with_lock "install.$p" 600 install_one_inner "$p" "$a"
  done
  ok "rebuild-all: OK"
}
rebuild_all_installed() { require_root; with_lock "db" 600 rebuild_all_installed_inner; }

###############################################################################
# Comandos: list/status/verify/doctor/clean-cache/lint/search/info/download
###############################################################################
cmd_list() {
  for d in "$INST_DIR"/*; do
    [ -d "$d" ] || continue
    p=$(basename "$d")
    v=$(installed_version "$p" 2>/dev/null || echo "?")
    a=$(installed_auto "$p" 2>/dev/null || echo 0)
    if [ "$a" = "1" ]; then printf '%s %s %s\n' "[auto]" "$p" "$v"
    else printf '%s %s %s\n' "[man ]" "$p" "$v"
    fi
  done | sort
}

cmd_status() {
  if [ $# -eq 0 ]; then
    for d in "$INST_DIR"/*; do
      [ -d "$d" ] || continue
      p=$(basename "$d")
      iv=$(installed_version "$p" 2>/dev/null || echo "?")
      rp=$(resolve_pkg_path "$p" 2>/dev/null || true)
      if [ -n "$rp" ]; then
        rv=$(read_version "$rp")
        if [ "$iv" = "$rv" ]; then printf '%s %s installed=%s repo=%s\n' "[=]" "$p" "$iv" "$rv"
        else printf '%s %s installed=%s repo=%s\n' "[!]" "$p" "$iv" "$rv"
        fi
      else
        printf '%s %s installed=%s repo=(missing)\n' "[?]" "$p" "$iv"
      fi
    done | sort
    return 0
  fi

  pkg="$1"
  iv=""
  if is_installed "$pkg"; then iv=$(installed_version "$pkg" 2>/dev/null || echo "?"); fi
  rp=$(resolve_pkg_path "$pkg" 2>/dev/null || true)
  if [ -n "$rp" ]; then rv=$(read_version "$rp"); else rv="(missing)"; fi

  if [ -n "$iv" ]; then
    [ "$iv" = "$rv" ] && say "[=] $pkg installed=$iv repo=$rv" || say "[!] $pkg installed=$iv repo=$rv"
  else
    say "[ ] $pkg installed=(no) repo=$rv"
  fi
}

cmd_verify() {
  pkg="${1:-}"; [ -n "$pkg" ] || die "Uso: adm verify <pkg>"
  is_installed "$pkg" || die "Não instalado: $pkg"
  idir="$INST_DIR/$pkg"
  mf="$idir/manifest"
  [ -f "$mf" ] || die "manifest ausente: $mf"

  missing=0
  while IFS= read -r f; do
    [ -n "$f" ] || continue
    if [ ! -e "/$f" ] && [ ! -L "/$f" ]; then
      printf '%s %s\n' "MISSING" "/$f"
      missing=$((missing + 1))
    fi
  done <"$mf"

  hash_fail=0
  fh="$idir/filehashes"
  if [ -s "$fh" ]; then
    alg=$(awk -F= 'NR==1 && $1=="ALG"{print $2}' "$fh" 2>/dev/null || echo "")
    if [ -n "$alg" ]; then
      awk 'NR>1{print}' "$fh" | while IFS="$(printf '\t')" read -r t h p; do
        [ -n "$t" ] && [ -n "$p" ] || continue
        if [ "$t" = "L" ]; then
          cur=$(readlink "/$p" 2>/dev/null || echo "")
          [ "$cur" = "$h" ] || { printf '%s %s\n' "LINK_MISMATCH" "/$p"; hash_fail=1; }
        elif [ "$t" = "F" ]; then
          if [ -f "/$p" ]; then
            cur=$(hash_file_kind "$alg" "/$p" 2>/dev/null || echo "")
            [ "$cur" = "$h" ] || { printf '%s %s\n' "HASH_MISMATCH" "/$p"; hash_fail=1; }
          fi
        fi
      done
    fi
  fi

  if [ "$missing" -eq 0 ] && [ "$hash_fail" -eq 0 ]; then
    ok "verify: $pkg OK"
  else
    warn "verify: $pkg missing=$missing hash_mismatch=$hash_fail"
    return 1
  fi
}

cmd_doctor() {
  ensure_dirs
  say "${C_BOLD}adm doctor${C_RESET}"

  # essenciais
  for c in sh tar awk sed grep sort find; do
    command -v "$c" >/dev/null 2>&1 && printf '%s %s\n' "[OK]" "$c" || printf '%s %s\n' "[!!]" "$c"
  done

  # compressões conforme uso
  command -v xz   >/dev/null 2>&1 && printf '%s %s\n' "[OK]" "xz"   || printf '%s %s\n' "[!!]" "xz"
  command -v gzip >/dev/null 2>&1 && printf '%s %s\n' "[OK]" "gzip" || printf '%s %s\n' "[..]" "gzip (necessário p/ .tar.gz)"
  command -v bzip2 >/dev/null 2>&1 && printf '%s %s\n' "[OK]" "bzip2" || printf '%s %s\n' "[..]" "bzip2 (necessário p/ .tar.bz2)"

  # download
  if command -v curl >/dev/null 2>&1 || command -v wget >/dev/null 2>&1; then
    printf '%s %s\n' "[OK]" "curl/wget"
  else
    printf '%s %s\n' "[!!]" "curl/wget"
  fi

  # sums
  if command -v sha256sum >/dev/null 2>&1 || command -v md5sum >/dev/null 2>&1; then
    printf '%s %s\n' "[OK]" "sha256sum/md5sum"
  else
    printf '%s %s\n' "[!!]" "sha256sum/md5sum"
  fi

  [ -f "$INDEX_CACHE" ] && printf '%s %s\n' "[OK]" "index cache" || { printf '%s %s\n' "[..]" "index cache (gerando)"; build_index; }

  bad=0
  for d in "$INST_DIR"/*; do
    [ -d "$d" ] || continue
    p=$(basename "$d")
    [ -f "$d/meta" ] || { printf '%s %s\n' "[!!]" "meta ausente: $p"; bad=$((bad+1)); }
    [ -f "$d/manifest" ] || { printf '%s %s\n' "[!!]" "manifest ausente: $p"; bad=$((bad+1)); }
  done

  [ "$bad" -eq 0 ] && ok "doctor: DB OK" || { warn "doctor: DB com $bad problemas"; return 1; }
}

cmd_clean_cache_inner() {
  do_sources=0; do_bins=0; do_work=0
  [ $# -eq 0 ] && do_work=1
  while [ $# -gt 0 ]; do
    case "$1" in
      --sources) do_sources=1 ;;
      --bins) do_bins=1 ;;
      --work) do_work=1 ;;
      --all) do_sources=1; do_bins=1; do_work=1 ;;
      *) die "Uso: adm clean-cache [--sources] [--bins] [--work] [--all]" ;;
    esac
    shift
  done
  [ "$do_work" -eq 1 ] && { info "limpando work: $WORK_DIR"; run "rm -rf '$WORK_DIR'/*"; }
  [ "$do_sources" -eq 1 ] && { info "limpando sources cache: $SRC_CACHE"; run "rm -rf '$SRC_CACHE'/*"; }
  [ "$do_bins" -eq 1 ] && { info "limpando bin cache: $BIN_CACHE"; run "rm -rf '$BIN_CACHE'/*"; }
  ok "clean-cache: OK"
}
cmd_clean_cache() { with_lock "cache" 600 cmd_clean_cache_inner "$@"; }

cmd_lint() {
  pkg="${1:-}"; [ -n "$pkg" ] || die "Uso: adm lint <pkg>"
  p=$(resolve_pkg_path "$pkg"); [ -n "$p" ] || die "Não encontrado: $pkg"
  fail=0

  for f in build version sources; do
    [ -f "$p/$f" ] && printf '%s %s\n' "[OK]" "$f" || { printf '%s %s\n' "[!!]" "faltando $f"; fail=$((fail+1)); }
  done

  v=$(read_version "$p" 2>/dev/null || echo "")
  [ -n "$v" ] && printf '%s %s\n' "[OK]" "version=$v" || { printf '%s %s\n' "[!!]" "version inválida"; fail=$((fail+1)); }

  s=$(list_sources_raw_lines "$p" | awk 'END{print NR+0}')
  [ "$s" -gt 0 ] && printf '%s %s\n' "[OK]" "sources linhas=$s" || { printf '%s %s\n' "[!!]" "sources vazio"; fail=$((fail+1)); }

  if [ -f "$p/checksums" ]; then
    bad=$(awk 'NF<2{b++} END{print b+0}' "$p/checksums")
    [ "$bad" -eq 0 ] && printf '%s %s\n' "[OK]" "checksums formato" || { printf '%s %s\n' "[!!]" "checksums com $bad linhas inválidas"; fail=$((fail+1)); }
  else
    printf '%s %s\n' "[..]" "checksums ausente (permitido, não recomendado)"
  fi

  if [ -f "$p/depends" ]; then
    for d in $(list_depends "$p"); do
      rp=$(resolve_pkg_path "$d" 2>/dev/null || true)
      [ -n "$rp" ] && printf '%s %s\n' "[OK]" "dep $d" || { printf '%s %s\n' "[!!]" "dep não encontrada: $d"; fail=$((fail+1)); }
    done
    deps_toposort "$pkg" >/dev/null 2>&1 || { printf '%s %s\n' "[!!]" "ciclo em deps"; fail=$((fail+1)); }
  fi

  [ "$fail" -eq 0 ] && ok "lint: $pkg OK" || { warn "lint: $pkg com $fail problemas"; return 1; }
}

cmd_search() {
  pat="${1:-}"; [ -n "$pat" ] || die "Uso: adm search <texto>"
  [ -f "$INDEX_CACHE" ] || build_index
  awk -F'\t' -v q="$pat" '
    BEGIN{qq=tolower(q)}
    { if (index(tolower($1), qq) || index(tolower($2), qq)) print $1 "\t" $2 }
  ' "$INDEX_CACHE" | while IFS="$(printf '\t')" read -r n c; do
    if is_installed "$n"; then printf '%s %s/%s\n' "[ ✔️]" "$c" "$n"
    else printf '%s %s/%s\n' "[   ]" "$c" "$n"
    fi
  done
}

cmd_info() {
  pkg="${1:-}"; [ -n "$pkg" ] || die "Uso: adm info <programa>"
  p=$(resolve_pkg_path "$pkg"); [ -n "$p" ] || die "Não encontrado: $pkg"
  v=$(read_version "$p")
  c=$(resolve_pkg_cat "$pkg")
  say "${C_BOLD}$pkg${C_RESET}  ${C_DIM}${c}/${pkg}${C_RESET}"
  say "version(repo): $v"
  if is_installed "$pkg"; then
    iv=$(installed_version "$pkg" 2>/dev/null || true)
    say "installed: [ ✔️ ] version=$iv"
  else
    say "installed: [   ]"
  fi
  if [ -f "$p/depends" ]; then say "depends:"; list_depends "$p" | sed 's/^/  - /'
  else say "depends: (nenhum)"
  fi
  if [ -f "$p/sources" ]; then say "sources:"; list_sources_raw_lines "$p" | sed 's/^/  - /'; fi
}

cmd_download() {
  pkg="${1:-}"; [ -n "$pkg" ] || die "Uso: adm download <programa>"
  pkgpath=$(resolve_pkg_path "$pkg"); [ -n "$pkgpath" ] || die "Não encontrado: $pkg"
  ensure_dirs
  dld="$WORK_DIR/download-only/$(sanitize_name "$pkg").$$"
  run "mkdir -p '$dld'"
  info "download: ${C_BOLD}$pkg${C_RESET}"
  with_lock "cache.sources.$pkg" 600 download_sources_parallel "$pkg" "$pkgpath" "$dld"
  ok "downloads em: $dld"
}

###############################################################################
# CLI
###############################################################################
usage() {
  cat <<EOF
adm — POSIX (repo local)

Comandos:
  adm help
  adm index
  adm search|s <texto>
  adm info|in <programa>
  adm download|d <programa>
  adm build|b <programa> [outros...]
  adm install|i <programa>              (root)
  adm remove|r <programa>               (root)
  adm orphans|orph                      (root)
  adm update|u
  adm rebuild-all|ra                    (root)

  adm list
  adm status [programa]
  adm verify <programa>
  adm doctor
  adm clean-cache [--sources] [--bins] [--work] [--all]
  adm lint <programa>

Flags:
  -n, --dry-run
  -S, --skip-checksums
  -f, --force
  --no-color
  -j N                (downloads paralelos; default: DL_JOBS=$DL_JOBS)
  -P N                (builds paralelos para "adm build pkg1 pkg2 ..."; default: BUILD_PARALLEL=$BUILD_PARALLEL)
EOF
}

main() {
  ensure_dirs

  while [ $# -gt 0 ]; do
    case "$1" in
      -n|--dry-run) DRYRUN=1; shift ;;
      -S|--skip-checksums) SKIP_SUMS=1; shift ;;
      -f|--force) FORCE=1; shift ;;
      --no-color) NO_COLOR=1; shift ;;
      -j) shift; DL_JOBS=${1:-4}; shift ;;
      -P) shift; BUILD_PARALLEL=${1:-1}; shift ;;
      --) shift; break ;;
      *) break ;;
    esac
  done

  init_colors

  need_cmd tar
  need_cmd awk
  need_cmd sed
  need_cmd grep
  need_cmd sort
  need_cmd find

  cmd=${1:-help}
  [ $# -gt 0 ] && shift || true

  case "$cmd" in
    help|-h|--help) usage ;;
    index) build_index ;;
    search|s) cmd_search "${1:-}" ;;
    info|in) cmd_info "${1:-}" ;;
    download|d) cmd_download "${1:-}" ;;
    build|b) build_many "$@" ;;
    install|i) install_one "${1:-}" 0 ;;
    remove|r) remove_one "${1:-}" ;;
    orphans|orph) remove_orphans ;;
    update|u) repo_update ;;
    rebuild-all|ra) rebuild_all_installed ;;

    list) cmd_list ;;
    status) cmd_status "$@" ;;
    verify) cmd_verify "${1:-}" ;;
    doctor) cmd_doctor ;;
    clean-cache) cmd_clean_cache "$@" ;;
    lint) cmd_lint "${1:-}" ;;

    *) die "Comando desconhecido: $cmd (use: adm help)" ;;
  esac
}

main "$@"
