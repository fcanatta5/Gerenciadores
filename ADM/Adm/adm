#!/bin/sh
# adm — POSIX package manager (repo local) com:
# - build simples (recebe DESTDIR em $1); adm faz download/cache/checksum/extract/patch/files/hooks/package/registro
# - checksums por arquivo (sha256 OU md5) com cache correto
# - parsing de sources por linha com #commit= e #branch=
# - download paralelo (por pacote) + opção de paralelismo de builds (limitado por locks)
# - locks POSIX via lockdir
# - instalação transacional básica (staging + backup/rollback)
# - comandos: doctor, verify, list, status, clean-cache, lint
#
# Layout do repo:
#   /var/src/adm/packages/<categoria>/<programa>/
#     build version checksums depends sources patch/ files/ hooks/ queue-status
#
# Hooks em hooks/ (executáveis):
#   pre-source post-source pre-extract post-extract pre-build post-build pre-install post-install pre-remove post-remove post-package pre-update post-update
# queue-status (executável) recebe PKG_EVENT=<evento>

set -eu

###############################################################################
# Config
###############################################################################
ADM_ROOT=${ADM_ROOT:-/var/src/adm}
REPO_DIR=${REPO_DIR:-"$ADM_ROOT/packages"}

WORK_DIR=${WORK_DIR:-/var/tmp/adm/work}
SRC_CACHE=${SRC_CACHE:-/var/cache/adm/sources}
BIN_CACHE=${BIN_CACHE:-/var/cache/adm/bins}

DB_DIR=${DB_DIR:-/var/lib/adm}
INST_DIR=$DB_DIR/installed
INDEX_CACHE=$DB_DIR/index.tsv
LOCK_DIR=$DB_DIR/locks
STATE_DIR=$DB_DIR/state

LOG_DIR=${LOG_DIR:-/var/log/adm}

PREFIX=${PREFIX:-/usr/local}
UMASK=${UMASK:-022}

DRYRUN=0
SKIP_SUMS=0
FORCE=0
NO_COLOR=0

DL_JOBS=${DL_JOBS:-4}          # paralelismo de downloads (sources do pacote)
BUILD_PARALLEL=${BUILD_PARALLEL:-1}  # paralelismo de builds (quando aplicável)

umask "$UMASK"

###############################################################################
# UI
###############################################################################
if [ -t 1 ] && [ "$NO_COLOR" -eq 0 ]; then
  C_RESET=$(printf '\033[0m')
  C_BOLD=$(printf '\033[1m')
  C_DIM=$(printf '\033[2m')
  C_RED=$(printf '\033[31m')
  C_GRN=$(printf '\033[32m')
  C_YEL=$(printf '\033[33m')
  C_CYN=$(printf '\033[36m')
else
  C_RESET=; C_BOLD=; C_DIM=; C_RED=; C_GRN=; C_YEL=; C_CYN=
fi

say()  { printf '%s\n' "$*"; }
info() { say "${C_CYN}[INFO]${C_RESET} $*"; }
ok()   { say "${C_GRN}[OK]${C_RESET}   $*"; }
warn() { say "${C_YEL}[WARN]${C_RESET} $*"; }
err()  { say "${C_RED}[ERRO]${C_RESET} $*" >&2; }
die()  { err "$*"; exit 1; }

run() {
  if [ "$DRYRUN" -eq 1 ]; then
    say "${C_DIM}DRY-RUN:${C_RESET} $*"
    return 0
  fi
  # shellcheck disable=SC2086
  sh -c "$*"
}

need_cmd() { command -v "$1" >/dev/null 2>&1 || die "Comando ausente: $1"; }
require_root() { [ "$(id -u)" -eq 0 ] || die "Este comando precisa de root."; }

ensure_dirs() {
  run "mkdir -p '$WORK_DIR' '$SRC_CACHE' '$BIN_CACHE' '$DB_DIR' '$INST_DIR' '$LOCK_DIR' '$STATE_DIR' '$LOG_DIR'"
}

ts() { date '+%Y-%m-%d %H:%M:%S'; }
log_path_for() { printf '%s/%s-%s.log\n' "$LOG_DIR" "$1" "$(date '+%Y%m%d-%H%M%S')"; }
sanitize_name() { printf '%s' "$1" | sed 's/[^A-Za-z0-9._+-]/_/g'; }

###############################################################################
# Locks (POSIX lockdir)
###############################################################################
lock_acquire() {
  # $1=name $2=timeout_seconds (0 = sem timeout)
  ensure_dirs
  name=$(sanitize_name "$1")
  tout=${2:-0}
  l="$LOCK_DIR/$name.lock"
  start=$(date +%s 2>/dev/null || echo 0)

  while :; do
    if mkdir "$l" 2>/dev/null; then
      if [ "$DRYRUN" -eq 0 ]; then
        printf '%s\n' "$$" >"$l/pid" 2>/dev/null || true
        printf '%s\n' "$(ts)" >"$l/time" 2>/dev/null || true
      fi
      return 0
    fi
    if [ "$tout" -gt 0 ]; then
      now=$(date +%s 2>/dev/null || echo 0)
      # se date +%s não existir, timeout não é garantido; ainda assim espera
      if [ "$start" -ne 0 ] && [ "$now" -ne 0 ] && [ $((now - start)) -ge "$tout" ]; then
        die "timeout aguardando lock: $name"
      fi
    fi
    sleep 1
  done
}

lock_release() {
  name=$(sanitize_name "$1")
  l="$LOCK_DIR/$name.lock"
  if [ "$DRYRUN" -eq 0 ]; then
    rmdir "$l" 2>/dev/null || true
  else
    say "${C_DIM}DRY-RUN:${C_RESET} release lock $name"
  fi
}

with_lock() {
  # $1=lockname $2=timeout $3=command...
  lk="$1"; tout="$2"; shift 2
  lock_acquire "$lk" "$tout"
  # shellcheck disable=SC2064
  trap "lock_release '$lk'" INT TERM EXIT
  "$@"
  trap - INT TERM EXIT
  lock_release "$lk"
}

###############################################################################
# Installed DB
###############################################################################
is_installed() { [ -d "$INST_DIR/$1" ]; }

installed_version() {
  [ -f "$INST_DIR/$1/meta" ] || return 1
  awk -F= '$1=="version"{print $2; exit}' "$INST_DIR/$1/meta"
}

installed_auto() {
  [ -f "$INST_DIR/$1/meta" ] || return 1
  awk -F= '$1=="auto"{print $2; exit}' "$INST_DIR/$1/meta"
}

###############################################################################
# Repo index
###############################################################################
build_index() {
  ensure_dirs
  info "Indexando: ${C_BOLD}$REPO_DIR${C_RESET}"
  tmp="$STATE_DIR/index.$$.tmp"
  if [ "$DRYRUN" -eq 0 ]; then
    find "$REPO_DIR" -mindepth 2 -maxdepth 2 -type d 2>/dev/null \
      | while IFS= read -r d; do
          n=$(basename "$d")
          c=$(basename "$(dirname "$d")")
          printf '%s\t%s\t%s\n' "$n" "$c" "$d"
        done | sort -u >"$tmp"
    mv "$tmp" "$INDEX_CACHE"
  else
    say "${C_DIM}DRY-RUN:${C_RESET} find '$REPO_DIR' ... > '$INDEX_CACHE'"
  fi
  ok "Index pronto: $INDEX_CACHE"
}

resolve_pkg_path() {
  [ -f "$INDEX_CACHE" ] || build_index
  awk -F'\t' -v p="$1" '$1==p{print $3; exit}' "$INDEX_CACHE"
}

resolve_pkg_cat() {
  [ -f "$INDEX_CACHE" ] || build_index
  awk -F'\t' -v p="$1" '$1==p{print $2; exit}' "$INDEX_CACHE"
}

resolve_pkg_ambiguous_count() {
  [ -f "$INDEX_CACHE" ] || build_index
  awk -F'\t' -v p="$1" '$1==p{c++} END{print c+0}' "$INDEX_CACHE"
}

resolve_pkg_ambiguous_list() {
  [ -f "$INDEX_CACHE" ] || build_index
  awk -F'\t' -v p="$1" '$1==p{print $2 "\t" $3}' "$INDEX_CACHE"
}

###############################################################################
# Recipe I/O
###############################################################################
read_version() {
  [ -f "$1/version" ] || die "version ausente: $1"
  sed -n '1p' "$1/version" | tr -d '\r\n'
}

list_depends() {
  if [ -f "$1/depends" ]; then
    sed 's/#.*$//' "$1/depends" | awk 'NF{print $1}'
  fi
}

list_sources_lines() {
  # preserva linha inteira (para suportar #commit/#branch)
  if [ -f "$1/sources" ]; then
    sed 's/[[:space:]]*$//' "$1/sources" | sed 's/#.*$//; /^$/d'
  fi
}

list_sources_raw() {
  # mantém fragmento #commit=... #branch=...
  if [ -f "$1/sources" ]; then
    sed 's/[[:space:]]*$//' "$1/sources" | sed '/^[[:space:]]*#/d; /^$/d'
  fi
}

###############################################################################
# Hooks + queue-status
###############################################################################
run_queue_status() {
  qs="$1/queue-status"
  ev="$2"
  if [ -f "$qs" ] && [ -x "$qs" ]; then
    info "queue-status: ${C_BOLD}$ev${C_RESET}"
    run "PKG_EVENT='$ev' '$qs'"
  fi
}

run_hook() {
  h="$1/hooks/$2"
  if [ -f "$h" ] && [ -x "$h" ]; then
    info "hook: ${C_BOLD}$2${C_RESET}"
    run "PKG_HOOK='$2' '$h'"
  fi
}

###############################################################################
# Checksums (por arquivo; sha256 ou md5; sem bug multi-download)
###############################################################################
hash_kind_from_hash() { case "${#1}" in 64) echo sha256 ;; 32) echo md5 ;; *) echo "" ;; esac; }
sum_cmd_for() {
  case "$1" in
    sha256) command -v sha256sum >/dev/null 2>&1 && echo sha256sum || echo "" ;;
    md5)    command -v md5sum    >/dev/null 2>&1 && echo md5sum    || echo "" ;;
    *)      echo "" ;;
  esac
}

checksum_expected_for_file() {
  # $1=checksums $2=filename -> hash
  awk -v f="$2" 'NF>=2{h=$1; file=$2; if(file==f){print h; exit}}' "$1"
}

verify_one_checksum() {
  # $1=checksumsfile $2=dir $3=filename
  [ "$SKIP_SUMS" -eq 1 ] && return 0
  csum="$1"; dir="$2"; f="$3"
  [ -f "$csum" ] || { warn "checksums ausente; pulando."; return 0; }

  exp=$(checksum_expected_for_file "$csum" "$f" | tr -d '\r')
  [ -n "$exp" ] || die "checksums não contém entrada para: $f"

  kind=$(hash_kind_from_hash "$exp")
  [ -n "$kind" ] || die "hash inválido em checksums para $f"

  cmd=$(sum_cmd_for "$kind")
  [ -n "$cmd" ] || die "Faltando ferramenta: $kind (precisa de ${kind}sum)."

  got=$((cd "$dir" && "$cmd" "$f") 2>/dev/null | awk '{print $1}')
  [ "$got" = "$exp" ]
}

# Consistência: checksums deve cobrir todos os arquivos baixados (quando checksums existe)
checksums_covers_file() {
  # $1=checksums $2=file -> 0 se existe linha para file
  awk -v f="$2" 'NF>=2{if($2==f){found=1}} END{exit found?0:1}' "$1"
}

###############################################################################
# Sources parsing (#commit= / #branch=) + download
###############################################################################
dl_tool() {
  if command -v curl >/dev/null 2>&1; then echo curl
  elif command -v wget >/dev/null 2>&1; then echo wget
  else echo ""
  fi
}

download_http_one() {
  tool=$(dl_tool)
  [ -n "$tool" ] || die "Precisa de curl ou wget."
  if [ "$tool" = curl ]; then
    run "curl -L --fail --retry 3 --retry-delay 1 --progress-bar -o '$2' '$1'"
  else
    run "wget --tries=3 --timeout=30 --progress=bar:force:noscroll -O '$2' '$1'"
  fi
}

url_strip_fragment() { printf '%s' "$1" | awk -F'#' '{print $1}'; }
url_fragment() { printf '%s' "$1" | awk -F'#' 'NF>=2{print $2}'; }
url_basename() { printf '%s' "$1" | sed 's/[?#].*$//' | awk -F/ '{print $NF}'; }

frag_get() {
  # $1=fragment string "a=1&b=2" (ou "a=1 b=2"); $2=key
  # aceita separadores & e espaço
  printf '%s' "$1" | tr '&' '\n' | tr ' ' '\n' | awk -F= -v k="$2" '$1==k{print $2; exit}'
}

hash_key() {
  if command -v sha256sum >/dev/null 2>&1; then
    printf '%s' "$1" | sha256sum | awk '{print $1}'
  else
    printf '%s' "$1" | md5sum | awk '{print $1}'
  fi
}

download_git_cached() {
  need_cmd git
  url="$1"; cachedir="$2"; branch="${3:-}"; commit="${4:-}"
  k=$(hash_key "$url")
  d="$cachedir/git-$k"

  if [ -d "$d/.git" ]; then
    info "git cache hit: ${C_BOLD}$url${C_RESET}"
    run "git -C '$d' fetch --all --prune"
  else
    info "git clone: ${C_BOLD}$url${C_RESET}"
    run "rm -rf '$d'"
    run "git clone --recursive '$url' '$d'"
  fi

  if [ -n "$branch" ]; then
    run "git -C '$d' checkout -f '$branch'"
    run "git -C '$d' pull --ff-only || true"
  fi

  if [ -n "$commit" ]; then
    run "git -C '$d' checkout -f '$commit'"
    # verificar HEAD == commit esperado
    if [ "$DRYRUN" -eq 0 ]; then
      head=$(git -C "$d" rev-parse HEAD 2>/dev/null || echo "")
      [ "$head" = "$commit" ] || die "git verify falhou: HEAD=$head esperado=$commit"
    fi
  fi

  echo "$d"
}

copy_cached_or_download_one() {
  # $1=pkg $2=pkgpath $3=source_line(raw) $4=outdir
  pkg="$1"; pkgpath="$2"; raw="$3"; outdir="$4"
  csum="$pkgpath/checksums"

  mkdir -p "$outdir" "$SRC_CACHE/$pkg"

  base=$(url_strip_fragment "$raw")
  frag=$(url_fragment "$raw")
  branch=$(frag_get "$frag" "branch" || true)
  commit=$(frag_get "$frag" "commit" || true)

  case "$base" in
    http://*|https://*|ftp://*)
      f=$(url_basename "$base")
      [ -n "$f" ] || die "URL inválida: $base"

      # Se checksums existe, exigir entrada para o arquivo
      if [ -f "$csum" ] && [ "$SKIP_SUMS" -eq 0 ]; then
        checksums_covers_file "$csum" "$f" || die "checksums não contém $f (obrigatório quando checksums existe)"
      fi

      cf="$SRC_CACHE/$pkg/$f"
      of="$outdir/$f"

      if [ -f "$cf" ]; then
        info "cache source: $pkg/$f"
        run "cp -f '$cf' '$of'"
        if verify_one_checksum "$csum" "$outdir" "$f"; then
          ok "checksum OK (cache): $f"
          return 0
        fi
        warn "checksum falhou (cache): $f; rebaixando"
        run "rm -f '$cf' '$of'"
      fi

      info "download: ${C_BOLD}$f${C_RESET}"
      download_http_one "$base" "$of"

      if verify_one_checksum "$csum" "$outdir" "$f"; then
        ok "checksum OK: $f"
        run "cp -f '$of' '$cf'"
      else
        run "rm -f '$of' '$cf'"
        die "checksum falhou após download: $f"
      fi
      ;;
    git:*|ssh://*|git@*:*|*".git"|git+*)
      d=$(download_git_cached "$base" "$SRC_CACHE/$pkg" "$branch" "$commit")
      k=$(basename "$d")
      run "rm -rf '$outdir/$k'"
      run "cp -a '$d' '$outdir/$k'"
      ;;
    *)
      die "source não suportada: $base"
      ;;
  esac
}

download_sources_parallel() {
  # Paralelo POSIX por pacote (pool com limite DL_JOBS)
  pkg="$1"; pkgpath="$2"; outdir="$3"
  srcs=$(list_sources_raw "$pkgpath" || true)
  [ -n "${srcs:-}" ] || { info "Sem sources."; return 0; }

  if [ "$DRYRUN" -eq 1 ]; then
    say "${C_DIM}DRY-RUN:${C_RESET} downloads (linhas):"
    printf '%s\n' "$srcs" | sed 's/^/  - /'
    return 0
  fi

  pids=""
  running=0

  # itera linha por linha sem quebrar URL por espaços (sources é “um por linha”)
  printf '%s\n' "$srcs" | while IFS= read -r raw; do
    (
      set -eu
      copy_cached_or_download_one "$pkg" "$pkgpath" "$raw" "$outdir"
    ) &
    pid=$!
    pids="$pids $pid"
    running=$((running + 1))

    if [ "$running" -ge "$DL_JOBS" ]; then
      first=$(printf '%s\n' "$pids" | awk '{print $1}')
      wait "$first" || exit 1
      pids=$(printf '%s\n' "$pids" | awk '{$1=""; sub(/^ /,""); print}')
      running=$((running - 1))
    fi
  done

  # aguarda o restante
  for pid in $pids; do
    wait "$pid" || die "Falha em download paralelo."
  done
}

###############################################################################
# Deps: topo + ciclo
###############################################################################
deps_toposort() {
  marks="$STATE_DIR/marks.$$.tmp"
  out="$STATE_DIR/order.$$.tmp"
  : >"$marks"
  : >"$out"

  dfs() {
    n="$1"
    if grep "^perm $n\$" "$marks" >/dev/null 2>&1; then return 0; fi
    if grep "^temp $n\$" "$marks" >/dev/null 2>&1; then die "Ciclo em dependências envolvendo: $n"; fi
    echo "temp $n" >>"$marks"

    p=$(resolve_pkg_path "$n")
    [ -n "$p" ] || die "Dependência não encontrada no repo: $n"
    for d in $(list_depends "$p"); do
      dfs "$d"
    done

    grep -v "^temp $n\$" "$marks" >"$marks.$$" && mv "$marks.$$" "$marks"
    echo "perm $n" >>"$marks"
    echo "$n" >>"$out"
  }

  dfs "$1"
  cat "$out"
  rm -f "$marks" "$out"
}

###############################################################################
# Extract + patch + files overlay
###############################################################################
extract_sources() {
  dld="$1"; srcd="$2"
  run "mkdir -p '$srcd'"

  g=$(find "$dld" -maxdepth 1 -type d -name 'git-*' 2>/dev/null | head -n 1 || true)
  if [ -n "$g" ]; then
    info "extract: git snapshot"
    run "rm -rf '$srcd/src' && mkdir -p '$srcd'"
    run "cp -a '$g' '$srcd/src'"
    echo "$srcd/src"
    return 0
  fi

  t=$(find "$dld" -maxdepth 1 -type f \
    \( -name '*.tar' -o -name '*.tar.gz' -o -name '*.tgz' -o -name '*.tar.bz2' -o -name '*.tbz2' -o -name '*.tar.xz' -o -name '*.txz' \) \
    2>/dev/null | head -n 1 || true)
  [ -n "$t" ] || die "Nenhum tarball encontrado em $dld"

  info "extract: $(basename "$t")"
  run "rm -rf '$srcd'/*"
  run "tar -xf '$t' -C '$srcd'"

  if [ "$DRYRUN" -eq 0 ]; then
    r=$(find "$srcd" -mindepth 1 -maxdepth 1 -type d 2>/dev/null | head -n 1 || true)
    [ -n "$r" ] || r="$srcd"
  else
    r="$srcd"
  fi
  echo "$r"
}

apply_patches_dir() {
  pkgpath="$1"; srcroot="$2"
  [ -d "$pkgpath/patch" ] || return 0
  command -v patch >/dev/null 2>&1 || { warn "patch ausente; ignorando patch/."; return 0; }

  found=0
  for p in "$pkgpath"/patch/*.patch "$pkgpath"/patch/*.diff; do
    [ -f "$p" ] || continue
    found=1
    info "patch: $(basename "$p")"
    run "patch -d '$srcroot' -p1 < '$p'"
  done
  [ "$found" -eq 1 ] || true
}

overlay_files_dir() {
  pkgpath="$1"; destdir="$2"
  [ -d "$pkgpath/files" ] || return 0
  if [ "$DRYRUN" -eq 0 ]; then
    if find "$pkgpath/files" -mindepth 1 -maxdepth 1 >/dev/null 2>&1; then
      info "overlay: files/ -> DESTDIR"
      run "cp -a '$pkgpath/files/.' '$destdir/'"
    fi
  else
    say "${C_DIM}DRY-RUN:${C_RESET} overlay files/ -> DESTDIR"
  fi
}

###############################################################################
# Packaging
###############################################################################
pkg_filename() {
  arch=$(uname -m 2>/dev/null || echo unknown)
  echo "$BIN_CACHE/$1-$2-$arch.tar.xz"
}

tar_supports_sort() { tar --help 2>/dev/null | grep ' --sort' >/dev/null 2>&1; }

package_destdir() {
  dest="$1"; pf="$2"; lf="$3"
  info "package: ${C_BOLD}$(basename "$pf")${C_RESET}"
  if [ "$DRYRUN" -eq 0 ]; then
    if tar_supports_sort; then
      (cd "$dest" && tar --sort=name --mtime='UTC 2020-01-01' --owner=0 --group=0 --numeric-owner -cf - .) \
        | xz -T0 -9e >"$pf" 2>>"$lf"
    else
      (cd "$dest" && tar -cf - .) | xz -T0 -9e >"$pf" 2>>"$lf"
    fi
  else
    say "${C_DIM}DRY-RUN:${C_RESET} tar|xz -> '$pf'"
  fi
}

manifest_from_tar() { tar -tf "$1" | sed 's|^\./||' | awk 'NF{print $0}' | sort -u; }

###############################################################################
# Ownership helpers (arquivos compartilhados)
###############################################################################
file_owned_by_other() {
  f="$1"; self="$2"
  for d in "$INST_DIR"/*; do
    [ -d "$d" ] || continue
    p=$(basename "$d")
    [ "$p" = "$self" ] && continue
    mf="$d/manifest"
    [ -f "$mf" ] || continue
    if grep -Fx "$f" "$mf" >/dev/null 2>&1; then
      return 0
    fi
  done
  return 1
}

###############################################################################
# Build core (alinhado ao seu modelo: build simples; adm passa DESTDIR em $1)
###############################################################################
build_one_inner() {
  pkg="$1"

  amb=$(resolve_pkg_ambiguous_count "$pkg")
  if [ "$amb" -gt 1 ]; then
    err "Programa ambíguo: $pkg"
    resolve_pkg_ambiguous_list "$pkg" | awk '{printf "  - %s (%s)\n", $2, $1}'
    die "Mantenha nomes únicos por categoria."
  fi

  pkgpath=$(resolve_pkg_path "$pkg")
  [ -n "$pkgpath" ] || die "Não encontrado no repo: $pkg"
  ver=$(read_version "$pkgpath")
  catg=$(resolve_pkg_cat "$pkg")
  pf=$(pkg_filename "$pkg" "$ver")

  if [ -f "$pf" ] && [ "$FORCE" -eq 0 ]; then
    ok "bin cache hit: $pf"
    return 0
  fi

  ensure_dirs
  lf=$(log_path_for "$pkg")

  info "build: ${C_BOLD}$pkg${C_RESET} ${C_DIM}($catg)${C_RESET} v${C_BOLD}$ver${C_RESET}"
  info "log:  ${C_BOLD}$lf${C_RESET}"

  b="$WORK_DIR/build/$(sanitize_name "$pkg")-$ver.$$"
  dld="$b/dl"
  srcd="$b/src"
  buildd="$b/build"
  dest="$b/dest"

  run "mkdir -p '$dld' '$srcd' '$buildd' '$dest'"

  export PKG="$pkg" VER="$ver" PKGPATH="$pkgpath"
  export WORK="$b" DL_DIR="$dld" SRC_DIR="$srcd" BUILD_DIR="$buildd" DESTDIR="$dest"
  export PREFIX="$PREFIX" DL_JOBS="$DL_JOBS" LOGFILE="$lf"

  {
    echo "== $(ts) :: build $pkg $ver =="
    echo "PKGPATH=$pkgpath"
    echo "WORK=$b"
    echo "PREFIX=$PREFIX"
    echo "DL_JOBS=$DL_JOBS"
  } >>"$lf"

  run_hook "$pkgpath" "pre-source"; run_queue_status "$pkgpath" "pre-source"
  download_sources_parallel "$pkg" "$pkgpath" "$dld" >>"$lf" 2>&1
  run_hook "$pkgpath" "post-source"; run_queue_status "$pkgpath" "post-source"

  run_hook "$pkgpath" "pre-extract"; run_queue_status "$pkgpath" "pre-extract"
  srcroot=$(extract_sources "$dld" "$srcd")
  export SRCROOT="$srcroot"
  run_hook "$pkgpath" "post-extract"; run_queue_status "$pkgpath" "post-extract"

  apply_patches_dir "$pkgpath" "$SRCROOT" >>"$lf" 2>&1

  run_hook "$pkgpath" "pre-build"; run_queue_status "$pkgpath" "pre-build"
  [ -f "$pkgpath/build" ] || die "build ausente: $pkgpath/build"

  info "run build: ${C_BOLD}$pkgpath/build${C_RESET}"
  if [ "$DRYRUN" -eq 0 ]; then
    (
      set -eu
      cd "$SRCROOT"
      if [ -x "$pkgpath/build" ]; then
        "$pkgpath/build" "$DESTDIR"
      else
        sh "$pkgpath/build" "$DESTDIR"
      fi
    ) >>"$lf" 2>&1 || die "Build falhou. Veja: $lf"
  else
    say "${C_DIM}DRY-RUN:${C_RESET} (cd '$SRCROOT' && sh '$pkgpath/build' '$DESTDIR')"
  fi
  run_hook "$pkgpath" "post-build"; run_queue_status "$pkgpath" "post-build"

  run_hook "$pkgpath" "pre-install"; run_queue_status "$pkgpath" "pre-install"
  overlay_files_dir "$pkgpath" "$DESTDIR" >>"$lf" 2>&1
  run_hook "$pkgpath" "post-install"; run_queue_status "$pkgpath" "post-install"

  run_hook "$pkgpath" "post-package"; run_queue_status "$pkgpath" "post-package"
  package_destdir "$DESTDIR" "$pf" "$lf"

  ok "build OK: $pkg v$ver"
  ok "bin: $pf"
}

build_one() {
  pkg="$1"
  with_lock "build.$pkg" 600 build_one_inner "$pkg"
}

###############################################################################
# Install transacional (staging + backup/rollback)
###############################################################################
install_tar_transact() {
  # $1=pkg $2=tarfile $3=logfile
  pkg="$1"; tf="$2"; lf="$3"

  [ -f "$tf" ] || die "pacote binário ausente: $tf"
  [ "$(id -u)" -eq 0 ] || die "instalação requer root"

  if [ "$DRYRUN" -eq 1 ]; then
    say "${C_DIM}DRY-RUN:${C_RESET} install transacional de '$tf' -> /"
    return 0
  fi

  stage="$STATE_DIR/stage.$pkg.$$"
  backup="$STATE_DIR/backup.$pkg.$$.tar"
  existed="$STATE_DIR/existed.$pkg.$$"
  newfiles="$STATE_DIR/newfiles.$pkg.$$"
  touchlist="$STATE_DIR/touch.$pkg.$$"

  mkdir -p "$stage"
  manifest_from_tar "$tf" >"$touchlist"

  # lista arquivos que já existem em / (para backup)
  : >"$existed"
  : >"$newfiles"
  while IFS= read -r f; do
    [ -n "$f" ] || continue
    case "$f" in
      *".."* ) continue ;;
    esac
    if [ -e "/$f" ] || [ -L "/$f" ]; then
      printf '%s\n' "$f" >>"$existed"
    else
      printf '%s\n' "$f" >>"$newfiles"
    fi
  done <"$touchlist"

  # 1) extrai pacote no stage
  if ! tar -xJf "$tf" -C "$stage" >>"$lf" 2>&1; then
    rm -rf "$stage" "$backup" "$existed" "$newfiles" "$touchlist"
    die "falha ao extrair pacote no stage"
  fi

  # 2) cria backup do que será sobrescrito (somente existentes)
  # (tar POSIX: lista via -T é comum, mas nem sempre; usamos pipeline)
  if [ -s "$existed" ]; then
    (
      cd /
      # cria tar com os paths existentes (sem o leading /)
      tar -cf "$backup" $(cat "$existed") 2>>"$lf"
    ) || {
      rm -rf "$stage" "$backup" "$existed" "$newfiles" "$touchlist"
      die "falha criando backup transacional"
    }
  else
    : >"$backup"
  fi

  # 3) aplica stage em / via tar pipe (preserva perms/links)
  if (cd "$stage" && tar -cf - .) | (cd / && tar -xf -) >>"$lf" 2>&1; then
    rm -rf "$stage" "$backup" "$existed" "$newfiles" "$touchlist"
    return 0
  fi

  # rollback
  warn "instalação falhou; iniciando rollback"
  # remove arquivos novos que não existiam antes
  if [ -s "$newfiles" ]; then
    while IFS= read -r f; do
      [ -n "$f" ] || continue
      rm -f "/$f" 2>/dev/null || true
    done <"$newfiles"
  fi
  # restaura backup
  if [ -s "$existed" ] && [ -s "$backup" ]; then
    (cd / && tar -xf "$backup") >>"$lf" 2>&1 || true
  fi

  rm -rf "$stage" "$backup" "$existed" "$newfiles" "$touchlist"
  die "instalação falhou e foi revertida"
}

###############################################################################
# Registro / remove
###############################################################################
record_installed_db() {
  pkg="$1"; ver="$2"; auto="$3"; pkgpath="$4"; pf="$5"
  idir="$INST_DIR/$pkg"
  mkdir -p "$idir"

  {
    echo "name=$pkg"
    echo "version=$ver"
    echo "category=$(resolve_pkg_cat "$pkg" 2>/dev/null || echo unknown)"
    echo "auto=$auto"
    echo "installed_at=$(ts)"
    echo "bin=$(basename "$pf")"
  } >"$idir/meta"

  if [ -f "$pkgpath/depends" ]; then
    sed 's/#.*$//' "$pkgpath/depends" | awk 'NF{print $1}' >"$idir/depends"
  else
    : >"$idir/depends"
  fi
}

reverse_deps() {
  target="$1"
  for d in "$INST_DIR"/*; do
    [ -d "$d" ] || continue
    p=$(basename "$d")
    depf="$d/depends"
    [ -f "$depf" ] || continue
    if grep -Fx "$target" "$depf" >/dev/null 2>&1; then
      echo "$p"
    fi
  done | sort -u
}

remove_files_from_manifest_delta() {
  pkg="$1"; oldmf="$2"; newmf="$3"

  [ "$DRYRUN" -eq 1 ] && { say "${C_DIM}DRY-RUN:${C_RESET} removeria delta antigo"; return 0; }

  awk 'FNR==NR{n[$0]=1; next} !n[$0]{print $0}' "$newmf" "$oldmf" \
    | while IFS= read -r f; do
        [ -n "$f" ] || continue
        case "$f" in *".."*) continue ;; esac
        file_owned_by_other "$f" "$pkg" && continue
        rm -f "/$f" 2>/dev/null || true
      done

  awk -F/ 'NF>1{p=""; for(i=1;i<NF;i++){p=p"/"$i; print p}}' "$oldmf" \
    | sort -u -r | while IFS= read -r d; do rmdir "/$d" 2>/dev/null || true; done
}

install_one_inner() {
  pkg="$1"; auto="${2:-0}"

  pkgpath=$(resolve_pkg_path "$pkg")
  [ -n "$pkgpath" ] || die "Não encontrado no repo: $pkg"
  ver=$(read_version "$pkgpath")
  pf=$(pkg_filename "$pkg" "$ver")
  lf=$(log_path_for "$pkg")

  # deps (ordem topo)
  info "deps: ${C_BOLD}$pkg${C_RESET}"
  for p in $(deps_toposort "$pkg"); do
    [ "$p" = "$pkg" ] && continue
    if ! is_installed "$p"; then
      with_lock "install.$p" 600 install_one_inner "$p" 1
    fi
  done

  # build se necessário
  if [ ! -f "$pf" ] || [ "$FORCE" -eq 1 ]; then
    build_one "$pkg"
  fi

  # hooks update (quando já instalado)
  if is_installed "$pkg"; then
    run_hook "$pkgpath" "pre-update"; run_queue_status "$pkgpath" "pre-update"
  fi

  run_hook "$pkgpath" "pre-install"; run_queue_status "$pkgpath" "pre-install"

  oldver=""
  oldmf_tmp="$STATE_DIR/$pkg.oldmf.$$"
  newmf_tmp="$STATE_DIR/$pkg.newmf.$$"

  if is_installed "$pkg"; then
    oldver=$(installed_version "$pkg" 2>/dev/null || true)
    [ -f "$INST_DIR/$pkg/manifest" ] && cp -f "$INST_DIR/$pkg/manifest" "$oldmf_tmp"
  fi

  info "install: ${C_BOLD}$pkg${C_RESET} v${C_BOLD}$ver${C_RESET}"
  install_tar_transact "$pkg" "$pf" "$lf"

  if [ "$DRYRUN" -eq 0 ]; then
    manifest_from_tar "$pf" >"$newmf_tmp"
    idir="$INST_DIR/$pkg"
    mkdir -p "$idir"
    cp -f "$newmf_tmp" "$idir/manifest"
    record_installed_db "$pkg" "$ver" "$auto" "$pkgpath" "$pf"
  fi

  run_hook "$pkgpath" "post-install"; run_queue_status "$pkgpath" "post-install"

  # post-update
  if [ -n "$oldver" ] && [ "$oldver" != "$ver" ]; then
    run_hook "$pkgpath" "post-update"; run_queue_status "$pkgpath" "post-update"
  fi

  # delta seguro (somente depois do novo instalado com sucesso)
  if [ -n "$oldver" ] && [ "$oldver" != "$ver" ] && [ -f "$oldmf_tmp" ] && [ -f "$newmf_tmp" ]; then
    info "upgrade: delta seguro $pkg v$oldver -> v$ver"
    remove_files_from_manifest_delta "$pkg" "$oldmf_tmp" "$newmf_tmp"
  fi

  rm -f "$oldmf_tmp" "$newmf_tmp" 2>/dev/null || true
  ok "instalado: $pkg v$ver"
}

install_one() {
  pkg="$1"; auto="${2:-0}"
  require_root
  with_lock "db" 600 true
  with_lock "install.$pkg" 600 install_one_inner "$pkg" "$auto"
}

remove_one_inner() {
  pkg="$1"
  is_installed "$pkg" || die "Não instalado: $pkg"

  pkgpath=$(resolve_pkg_path "$pkg" 2>/dev/null || true)
  if [ -n "${pkgpath:-}" ]; then
    run_hook "$pkgpath" "pre-remove"; run_queue_status "$pkgpath" "pre-remove"
  fi

  mf="$INST_DIR/$pkg/manifest"
  [ -f "$mf" ] || die "manifest ausente: $mf"

  info "remove: ${C_BOLD}$pkg${C_RESET}"

  if [ "$DRYRUN" -eq 0 ]; then
    # reverso POSIX
    awk '{a[NR]=$0} END{for(i=NR;i>=1;i--) print a[i]}' "$mf" \
      | while IFS= read -r f; do
          [ -n "$f" ] || continue
          case "$f" in *".."*) continue ;; esac
          file_owned_by_other "$f" "$pkg" && continue
          rm -f "/$f" 2>/dev/null || true
        done

    awk -F/ 'NF>1{p=""; for(i=1;i<NF;i++){p=p"/"$i; print p}}' "$mf" \
      | sort -u -r | while IFS= read -r d; do rmdir "/$d" 2>/dev/null || true; done

    rm -rf "$INST_DIR/$pkg"
  else
    say "${C_DIM}DRY-RUN:${C_RESET} removeria arquivos de $pkg"
  fi

  if [ -n "${pkgpath:-}" ]; then
    run_hook "$pkgpath" "post-remove" || true
    run_queue_status "$pkgpath" "post-remove" || true
  fi
  ok "removido: $pkg"
}

remove_one() {
  pkg="$1"
  require_root
  with_lock "install.$pkg" 600 remove_one_inner "$pkg"
}

remove_orphans() {
  require_root
  info "orphans: removendo auto=1 sem reverse-deps"
  changed=1
  while [ "$changed" -eq 1 ]; do
    changed=0
    for d in "$INST_DIR"/*; do
      [ -d "$d" ] || continue
      p=$(basename "$d")
      a=$(installed_auto "$p" 2>/dev/null || echo 0)
      [ "$a" = 1 ] || continue
      r=$(reverse_deps "$p" | awk 'END{print NR+0}')
      if [ "$r" -eq 0 ]; then
        warn "órfão: $p"
        remove_one "$p"
        changed=1
      fi
    done
  done
  ok "orphans: concluído"
}

###############################################################################
# Paralelismo de builds (multi-alvos)
###############################################################################
build_many() {
  # adm build pkg1 pkg2 ... com paralelismo BUILD_PARALLEL (locks por pacote)
  [ $# -gt 0 ] || die "Uso: adm build <pkg> [pkg...]"
  if [ "$BUILD_PARALLEL" -le 1 ] || [ "$DRYRUN" -eq 1 ]; then
    for p in "$@"; do build_one "$p"; done
    return 0
  fi

  pids=""
  running=0
  for p in "$@"; do
    ( set -eu; build_one "$p" ) &
    pid=$!
    pids="$pids $pid"
    running=$((running + 1))
    if [ "$running" -ge "$BUILD_PARALLEL" ]; then
      first=$(printf '%s\n' "$pids" | awk '{print $1}')
      wait "$first" || die "falha em build paralelo"
      pids=$(printf '%s\n' "$pids" | awk '{$1=""; sub(/^ /,""); print}')
      running=$((running - 1))
    fi
  done
  for pid in $pids; do wait "$pid" || die "falha em build paralelo"; done
}

###############################################################################
# Update / Rebuild-all (ordem topo)
###############################################################################
repo_update() {
  ensure_dirs
  with_lock "repo" 600 true
  if [ -d "$ADM_ROOT/.git" ]; then
    need_cmd git
    info "update: git pull em ${C_BOLD}$ADM_ROOT${C_RESET}"
    run "git -C '$ADM_ROOT' pull --ff-only"
    ok "update: OK"
  else
    warn "update: $ADM_ROOT não é git; pulando"
  fi
  build_index
}

rebuild_all_installed() {
  require_root
  info "rebuild-all: reconstruindo e reinstalando (ordem por deps)"
  # constrói conjunto world e ordena por deps via topo em “super nó”
  # abordagem simples: instala em sequência por lista de instalados ordenada por nome, mas respeita deps por instalação.
  for d in "$INST_DIR"/*; do
    [ -d "$d" ] || continue
    p=$(basename "$d")
    a=$(installed_auto "$p" 2>/dev/null || echo 0)
    install_one "$p" "$a"
  done
  ok "rebuild-all: OK"
}

###############################################################################
# Comandos novos: list, status, verify, doctor, clean-cache, lint
###############################################################################
cmd_list() {
  # lista instalados
  for d in "$INST_DIR"/*; do
    [ -d "$d" ] || continue
    p=$(basename "$d")
    v=$(installed_version "$p" 2>/dev/null || echo "?")
    a=$(installed_auto "$p" 2>/dev/null || echo 0)
    if [ "$a" = "1" ]; then
      printf '%s %s %s\n' "[auto]" "$p" "$v"
    else
      printf '%s %s %s\n' "[man ]" "$p" "$v"
    fi
  done | sort
}

cmd_status() {
  # status [pkg] : mostra instalado vs repo
  if [ $# -eq 0 ]; then
    for d in "$INST_DIR"/*; do
      [ -d "$d" ] || continue
      p=$(basename "$d")
      iv=$(installed_version "$p" 2>/dev/null || echo "?")
      rp=$(resolve_pkg_path "$p" 2>/dev/null || true)
      if [ -n "$rp" ]; then
        rv=$(read_version "$rp")
        if [ "$iv" = "$rv" ]; then
          printf '%s %s installed=%s repo=%s\n' "[=]" "$p" "$iv" "$rv"
        else
          printf '%s %s installed=%s repo=%s\n' "[!]" "$p" "$iv" "$rv"
        fi
      else
        printf '%s %s installed=%s repo=(missing)\n' "[?]" "$p" "$iv"
      fi
    done | sort
    return 0
  fi

  pkg="$1"
  iv=""
  if is_installed "$pkg"; then iv=$(installed_version "$pkg" 2>/dev/null || echo "?"); fi
  rp=$(resolve_pkg_path "$pkg" 2>/dev/null || true)
  if [ -n "$rp" ]; then rv=$(read_version "$rp"); else rv="(missing)"; fi
  if [ -n "$iv" ]; then
    if [ "$iv" = "$rv" ]; then
      say "[=] $pkg installed=$iv repo=$rv"
    else
      say "[!] $pkg installed=$iv repo=$rv"
    fi
  else
    say "[ ] $pkg installed=(no) repo=$rv"
  fi
}

cmd_verify() {
  # verify <pkg> : valida manifest vs filesystem (existência)
  pkg="${1:-}"
  [ -n "$pkg" ] || die "Uso: adm verify <pkg>"
  is_installed "$pkg" || die "Não instalado: $pkg"
  mf="$INST_DIR/$pkg/manifest"
  [ -f "$mf" ] || die "manifest ausente: $mf"

  missing=0
  while IFS= read -r f; do
    [ -n "$f" ] || continue
    case "$f" in *".."*) continue ;; esac
    if [ ! -e "/$f" ] && [ ! -L "/$f" ]; then
      printf '%s %s\n' "MISSING" "/$f"
      missing=$((missing + 1))
    fi
  done <"$mf"

  if [ "$missing" -eq 0 ]; then
    ok "verify: $pkg OK"
  else
    warn "verify: $pkg faltando $missing arquivos"
    return 1
  fi
}

cmd_doctor() {
  # checagens de ambiente/DB/repo
  ensure_dirs
  say "${C_BOLD}adm doctor${C_RESET}"
  # tools mínimos
  for c in sh tar xz awk sed grep sort find; do
    if command -v "$c" >/dev/null 2>&1; then
      printf '%s %s\n' "[OK]" "$c"
    else
      printf '%s %s\n' "[!!]" "$c"
    fi
  done

  # download tools
  if command -v curl >/dev/null 2>&1 || command -v wget >/dev/null 2>&1; then
    printf '%s %s\n' "[OK]" "curl/wget"
  else
    printf '%s %s\n' "[!!]" "curl/wget"
  fi

  # checksums tools
  if command -v sha256sum >/dev/null 2>&1 || command -v md5sum >/dev/null 2>&1; then
    printf '%s %s\n' "[OK]" "sha256sum/md5sum"
  else
    printf '%s %s\n' "[!!]" "sha256sum/md5sum"
  fi

  # index
  if [ -f "$INDEX_CACHE" ]; then
    printf '%s %s\n' "[OK]" "index cache"
  else
    printf '%s %s\n' "[..]" "index cache (gerando)"
    build_index
  fi

  # DB consistency
  bad=0
  for d in "$INST_DIR"/*; do
    [ -d "$d" ] || continue
    p=$(basename "$d")
    [ -f "$d/meta" ] || { printf '%s %s\n' "[!!]" "meta ausente: $p"; bad=$((bad+1)); }
    [ -f "$d/manifest" ] || { printf '%s %s\n' "[!!]" "manifest ausente: $p"; bad=$((bad+1)); }
  done
  if [ "$bad" -eq 0 ]; then
    ok "doctor: DB OK"
  else
    warn "doctor: DB com $bad problemas"
    return 1
  fi
}

cmd_clean_cache() {
  # clean-cache [--sources] [--bins] [--work] [--all]
  do_sources=0; do_bins=0; do_work=0
  if [ $# -eq 0 ]; then do_work=1; fi
  while [ $# -gt 0 ]; do
    case "$1" in
      --sources) do_sources=1 ;;
      --bins) do_bins=1 ;;
      --work) do_work=1 ;;
      --all) do_sources=1; do_bins=1; do_work=1 ;;
      *) die "Uso: adm clean-cache [--sources] [--bins] [--work] [--all]" ;;
    esac
    shift
  done

  with_lock "cache" 600 true

  if [ "$do_work" -eq 1 ]; then
    info "limpando work: $WORK_DIR"
    run "rm -rf '$WORK_DIR'/*"
  fi
  if [ "$do_sources" -eq 1 ]; then
    info "limpando sources cache: $SRC_CACHE"
    run "rm -rf '$SRC_CACHE'/*"
  fi
  if [ "$do_bins" -eq 1 ]; then
    info "limpando bin cache: $BIN_CACHE"
    run "rm -rf '$BIN_CACHE'/*"
  fi
  ok "clean-cache: OK"
}

cmd_lint() {
  # lint <pkg>
  pkg="${1:-}"
  [ -n "$pkg" ] || die "Uso: adm lint <pkg>"
  p=$(resolve_pkg_path "$pkg")
  [ -n "$p" ] || die "Não encontrado: $pkg"

  fail=0

  req="build version sources"
  for f in $req; do
    if [ ! -f "$p/$f" ]; then
      printf '%s %s\n' "[!!]" "faltando $f"
      fail=$((fail+1))
    else
      printf '%s %s\n' "[OK]" "$f"
    fi
  done

  # version: 1 linha não vazia
  v=$(read_version "$p" 2>/dev/null || echo "")
  if [ -n "$v" ]; then
    printf '%s %s\n' "[OK]" "version=$v"
  else
    printf '%s %s\n' "[!!]" "version inválida"
    fail=$((fail+1))
  fi

  # sources: uma por linha, não vazia
  s=$(list_sources_raw "$p" | awk 'END{print NR+0}')
  if [ "$s" -gt 0 ]; then
    printf '%s %s\n' "[OK]" "sources linhas=$s"
  else
    printf '%s %s\n' "[!!]" "sources vazio"
    fail=$((fail+1))
  fi

  # checksums: se existir, cada linha deve ter hash + arquivo
  if [ -f "$p/checksums" ]; then
    bad=$(awk 'NF<2{b++} END{print b+0}' "$p/checksums")
    if [ "$bad" -eq 0 ]; then
      printf '%s %s\n' "[OK]" "checksums formato"
    else
      printf '%s %s\n' "[!!]" "checksums com $bad linhas inválidas"
      fail=$((fail+1))
    fi
  else
    printf '%s %s\n' "[..]" "checksums ausente (permitido, mas não recomendado)"
  fi

  # depends: devem existir no index (quando index tem pkg)
  if [ -f "$p/depends" ]; then
    for d in $(list_depends "$p"); do
      rp=$(resolve_pkg_path "$d" 2>/dev/null || true)
      if [ -n "$rp" ]; then
        printf '%s %s\n' "[OK]" "dep $d"
      else
        printf '%s %s\n' "[!!]" "dep não encontrada no repo: $d"
        fail=$((fail+1))
      fi
    done
  fi

  if [ "$fail" -eq 0 ]; then
    ok "lint: $pkg OK"
  else
    warn "lint: $pkg com $fail problemas"
    return 1
  fi
}

###############################################################################
# Search / Info (case-insensitive POSIX)
###############################################################################
cmd_search() {
  pat="${1:-}"
  [ -n "$pat" ] || die "Uso: adm search <texto>"
  [ -f "$INDEX_CACHE" ] || build_index
  awk -F'\t' -v q="$pat" '
    BEGIN{qq=tolower(q)}
    { if (index(tolower($1), qq) || index(tolower($2), qq)) print $1 "\t" $2 }
  ' "$INDEX_CACHE" | while IFS="$(printf '\t')" read -r n c; do
    if is_installed "$n"; then
      printf '%s %s/%s\n' "[ ✔️]" "$c" "$n"
    else
      printf '%s %s/%s\n' "[   ]" "$c" "$n"
    fi
  done
}

cmd_info() {
  pkg="${1:-}"
  [ -n "$pkg" ] || die "Uso: adm info <programa>"
  p=$(resolve_pkg_path "$pkg")
  [ -n "$p" ] || die "Não encontrado: $pkg"

  v=$(read_version "$p")
  c=$(resolve_pkg_cat "$pkg")

  say "${C_BOLD}$pkg${C_RESET}  ${C_DIM}${c}/${pkg}${C_RESET}"
  say "version(repo): $v"
  if is_installed "$pkg"; then
    iv=$(installed_version "$pkg" 2>/dev/null || true)
    say "installed: [ ✔️ ] version=$iv"
  else
    say "installed: [   ]"
  fi

  if [ -f "$p/depends" ]; then
    say "depends:"
    list_depends "$p" | sed 's/^/  - /'
  else
    say "depends: (nenhum)"
  fi

  if [ -f "$p/sources" ]; then
    say "sources:"
    list_sources_raw "$p" | sed 's/^/  - /'
  fi
}

cmd_download() {
  pkg="${1:-}"
  [ -n "$pkg" ] || die "Uso: adm download <programa>"
  pkgpath=$(resolve_pkg_path "$pkg")
  [ -n "$pkgpath" ] || die "Não encontrado: $pkg"
  ensure_dirs
  dld="$WORK_DIR/download-only/$(sanitize_name "$pkg").$$"
  run "mkdir -p '$dld'"
  info "download: ${C_BOLD}$pkg${C_RESET}"
  download_sources_parallel "$pkg" "$pkgpath" "$dld"
  ok "downloads em: $dld"
}

###############################################################################
# CLI
###############################################################################
usage() {
  cat <<EOF
adm — POSIX (repo local)

Comandos:
  adm help
  adm index
  adm search|s <texto>
  adm info|in <programa>
  adm download|d <programa>
  adm build|b <programa> [outros...]
  adm install|i <programa>              (root)
  adm remove|r <programa>               (root)
  adm orphans|orph                      (root)
  adm update|u
  adm rebuild-all|ra                    (root)

  adm list
  adm status [programa]
  adm verify <programa>
  adm doctor
  adm clean-cache [--sources] [--bins] [--work] [--all]
  adm lint <programa>

Flags:
  -n, --dry-run
  -S, --skip-checksums
  -f, --force
  --no-color
  -j N                (downloads paralelos; default: DL_JOBS=$DL_JOBS)
  -P N                (builds paralelos para "adm build pkg1 pkg2 ..."; default: BUILD_PARALLEL=$BUILD_PARALLEL)

EOF
}

main() {
  ensure_dirs
  need_cmd tar
  need_cmd xz
  need_cmd awk
  need_cmd sed
  need_cmd grep
  need_cmd sort
  need_cmd find

  # flags
  while [ $# -gt 0 ]; do
    case "$1" in
      -n|--dry-run) DRYRUN=1; shift ;;
      -S|--skip-checksums) SKIP_SUMS=1; shift ;;
      -f|--force) FORCE=1; shift ;;
      --no-color) NO_COLOR=1; shift ;;
      -j) shift; DL_JOBS=${1:-4}; shift ;;
      -P) shift; BUILD_PARALLEL=${1:-1}; shift ;;
      --) shift; break ;;
      *) break ;;
    esac
  done

  cmd=${1:-help}
  [ $# -gt 0 ] && shift || true

  case "$cmd" in
    help|-h|--help) usage ;;
    index) build_index ;;
    search|s) cmd_search "${1:-}" ;;
    info|in) cmd_info "${1:-}" ;;
    download|d) cmd_download "${1:-}" ;;
    build|b) build_many "$@" ;;
    install|i) require_root; install_one "${1:-}" 0 ;;
    remove|r) require_root; remove_one "${1:-}" ;;
    orphans|orph) require_root; remove_orphans ;;
    update|u) repo_update ;;
    rebuild-all|ra) require_root; rebuild_all_installed ;;

    list) cmd_list ;;
    status) cmd_status "$@" ;;
    verify) cmd_verify "${1:-}" ;;
    doctor) cmd_doctor ;;
    clean-cache) cmd_clean_cache "$@" ;;
    lint) cmd_lint "${1:-}" ;;

    *) die "Comando desconhecido: $cmd (use: adm help)" ;;
  esac
}

main "$@"
