#!/bin/sh
# adm-pkg - minimal rolling package manager (POSIX sh)
# Target: x86_64-linux-musl
# No bashisms. No arrays. No process substitution. No [[ ]].

umask 022

###############################################################################
# Defaults (override via /etc/adm-pkg.conf and env)
###############################################################################
: "${ADM_ROOT:=/}"
: "${ADM_PKGS_DIR:=/usr/adm/packages}"
: "${ADM_DB_DIR:=/var/lib/adm-pkg}"
: "${ADM_CACHE_DIR:=/var/cache/adm-pkg}"
: "${ADM_SRC_CACHE:=$ADM_CACHE_DIR/sources}"
: "${ADM_BIN_CACHE:=$ADM_CACHE_DIR/binpkgs}"
: "${ADM_BUILD_DIR:=$ADM_CACHE_DIR/build}"
: "${ADM_LOG_DIR:=/var/log/adm-pkg}"
: "${ADM_JOBS:=1}"
: "${ADM_FETCH_CMD:=auto}"      # auto|curl|wget
: "${ADM_GIT_REPO_DIR:=/usr/adm}" # your git repo root (optional)
: "${ADM_STRIP:=1}"             # 1 or 0
: "${ADM_CFLAGS:=-O2 -pipe}"
: "${ADM_CXXFLAGS:=-O2 -pipe}"
: "${ADM_LDFLAGS:=-Wl,-O1}"
: "${ADM_MAKEFLAGS:=}"
: "${ADM_TAR:=tar}"
: "${ADM_ZSTD:=zstd}"
: "${ADM_XZ:=xz}"
: "${ADM_SHA256:=sha256sum}"
: "${ADM_MD5:=md5sum}"
: "${ADM_INSTALL:=install}"
: "${ADM_SED:=sed}"
: "${ADM_AWK:=awk}"
: "${ADM_GREP:=grep}"
: "${ADM_SORT:=sort}"
: "${ADM_FIND:=find}"
: "${ADM_CP:=cp}"
: "${ADM_RM:=rm}"
: "${ADM_MKDIR:=mkdir}"
: "${ADM_TOUCH:=touch}"
: "${ADM_DATE:=date}"
: "${ADM_GIT:=git}"
: "${ADM_LOCK_FD:=9}"

CONFIG_FILE="/etc/adm-pkg.conf"
[ -f "$CONFIG_FILE" ] && . "$CONFIG_FILE"

###############################################################################
# Helpers: logging, errors, locks
###############################################################################
die() { echo "adm-pkg: ERROR: $*" >&2; exit 1; }

msg() { echo "==> $*"; }

now() { "$ADM_DATE" '+%Y-%m-%d %H:%M:%S'; }

ensure_dir() { [ -d "$1" ] || "$ADM_MKDIR" -p "$1" || die "cannot create dir: $1"; }

log_init() {
  ensure_dir "$ADM_LOG_DIR"
  ensure_dir "$ADM_DB_DIR"
  ensure_dir "$ADM_CACHE_DIR"
  ensure_dir "$ADM_SRC_CACHE"
  ensure_dir "$ADM_BIN_CACHE"
  ensure_dir "$ADM_BUILD_DIR"
}

log_file_for() {
  # args: pkgname pkgver pkgrel
  echo "$ADM_LOG_DIR/$1-$2-r$3.log"
}

log() {
  # Always also write to stdout
  # If ADM_CURRENT_LOG is set, tee to it
  if [ -n "${ADM_CURRENT_LOG:-}" ]; then
    printf '%s %s\n' "$(now)" "$*" | tee -a "$ADM_CURRENT_LOG"
  else
    printf '%s %s\n' "$(now)" "$*"
  fi
}

need_cmd() {
  command -v "$1" >/dev/null 2>&1 || die "missing required command: $1"
}

with_lock() {
  ensure_dir "$ADM_DB_DIR"
  LOCKFILE="$ADM_DB_DIR/.lock"
  # POSIX sh has no flock builtin; use mkdir lock (atomic)
  # If stale lock: user can remove manually.
  i=0
  while ! "$ADM_MKDIR" "$LOCKFILE" 2>/dev/null; do
    i=$((i+1))
    [ "$i" -gt 200 ] && die "could not acquire lock: $LOCKFILE (stale?)"
    sleep 1
  done
  trap 'rmdir "$LOCKFILE" 2>/dev/null; exit 1' INT TERM HUP
}

unlock() {
  rmdir "$ADM_DB_DIR/.lock" 2>/dev/null
  trap - INT TERM HUP
}

###############################################################################
# Build script loading and package metadata
###############################################################################
pkg_path_from_name() {
  # input: name or category/name
  # output: absolute dir containing build script
  case "$1" in
    */*)
      p="$ADM_PKGS_DIR/$1"
      ;;
    *)
      # search by name across categories
      p=$("$ADM_FIND" "$ADM_PKGS_DIR" -mindepth 2 -maxdepth 2 -type d -name "$1" 2>/dev/null | "$ADM_SORT" | "$ADM_AWK" 'NR==1{print; exit}')
      ;;
  esac
  [ -n "$p" ] && [ -d "$p" ] || return 1
  [ -f "$p/build" ] || return 1
  echo "$p"
}

reset_pkg_vars() {
  PKGNAME=""
  PKGVER=""
  PKGREL="1"
  PKGDESC=""
  PKGURL=""
  LICENSE=""
  ARCH="x86_64"
  SECTION=""
  SOURCES=""
  SUMTYPE="sha256" # sha256|md5
  SUMS=""
  DEPENDS=""
  BUILD_DEPENDS=""
  CONFLICTS=""
  PROVIDES=""
  HOOKS=""
}

load_build_script() {
  # args: pkgdir
  reset_pkg_vars
  PKGDIR="$1"
  BUILDSCRIPT="$PKGDIR/build"
  [ -f "$BUILDSCRIPT" ] || die "build script not found: $BUILDSCRIPT"

  # shellcheck disable=SC1090
  . "$BUILDSCRIPT" || die "failed to source build script: $BUILDSCRIPT"

  [ -n "$PKGNAME" ] || die "PKGNAME not set in $BUILDSCRIPT"
  [ -n "$PKGVER" ] || die "PKGVER not set in $BUILDSCRIPT"
  [ -n "$PKGREL" ] || PKGREL="1"
  [ -n "$SECTION" ] || SECTION="$(basename "$(dirname "$PKGDIR")")"

  # Export common build env for build scripts
  export ADM_ROOT ADM_PKGS_DIR ADM_DB_DIR ADM_CACHE_DIR ADM_SRC_CACHE ADM_BIN_CACHE ADM_BUILD_DIR ADM_LOG_DIR
  export ADM_JOBS ADM_CFLAGS ADM_CXXFLAGS ADM_LDFLAGS ADM_MAKEFLAGS ADM_STRIP
  export PKGDIR BUILDSCRIPT PKGNAME PKGVER PKGREL SECTION PKGDESC PKGURL LICENSE ARCH
}

pkg_id() { echo "$PKGNAME-$PKGVER-r$PKGREL"; }

db_pkg_dir() { echo "$ADM_DB_DIR/pkgs/$PKGNAME"; }

db_installed_marker() { echo "$(db_pkg_dir)/installed"; }

db_manifest() { echo "$(db_pkg_dir)/manifest"; }

db_meta() { echo "$(db_pkg_dir)/meta"; }

is_installed() { [ -f "$(db_installed_marker)" ]; }

###############################################################################
# Fetching sources with cache + checksum validation
###############################################################################
pick_fetch_cmd() {
  case "$ADM_FETCH_CMD" in
    curl) need_cmd curl; echo "curl -L --fail -o" ;;
    wget) need_cmd wget; echo "wget -O" ;;
    auto)
      if command -v curl >/dev/null 2>&1; then
        echo "curl -L --fail -o"
      elif command -v wget >/dev/null 2>&1; then
        echo "wget -O"
      else
        die "need curl or wget for fetching"
      fi
      ;;
    *) die "invalid ADM_FETCH_CMD=$ADM_FETCH_CMD" ;;
  esac
}

checksum_file() {
  # args: sumtype file
  t="$1"; f="$2"
  case "$t" in
    sha256) need_cmd "$ADM_SHA256"; "$ADM_SHA256" "$f" | "$ADM_AWK" '{print $1}' ;;
    md5) need_cmd "$ADM_MD5"; "$ADM_MD5" "$f" | "$ADM_AWK" '{print $1}' ;;
    *) die "invalid SUMTYPE=$t (use sha256 or md5)" ;;
  esac
}

verify_sources() {
  # Uses SOURCES and SUMS aligned line-by-line.
  # SOURCES: lines of URLs or local paths (optional "name::url" supported).
  # SUMS: lines of expected sums.
  # SUMTYPE: sha256|md5
  ensure_dir "$ADM_SRC_CACHE"
  fetchcmd="$(pick_fetch_cmd)"

  src_list_file="$WORKDIR/.sources"
  sum_list_file="$WORKDIR/.sums"
  printf '%s\n' "$SOURCES" | "$ADM_SED" '/^[[:space:]]*$/d' >"$src_list_file"
  printf '%s\n' "$SUMS" | "$ADM_SED" '/^[[:space:]]*$/d' >"$sum_list_file"

  src_count=$("$ADM_AWK" 'END{print NR+0}' "$src_list_file")
  sum_count=$("$ADM_AWK" 'END{print NR+0}' "$sum_list_file")

  [ "$src_count" -eq "$sum_count" ] || die "SOURCES count ($src_count) != SUMS count ($sum_count) in $BUILDSCRIPT"

  i=1
  while [ "$i" -le "$src_count" ]; do
    src=$("$ADM_AWK" "NR==$i{print; exit}" "$src_list_file")
    exp=$("$ADM_AWK" "NR==$i{print; exit}" "$sum_list_file")

    # Support "name::url"
    case "$src" in
      *"::"*)
        name=$(printf '%s' "$src" | "$ADM_AWK" -F"::" '{print $1}')
        url=$(printf '%s' "$src" | "$ADM_AWK" -F"::" '{print $2}')
        ;;
      *)
        name=""
        url="$src"
        ;;
    esac

    # Determine filename
    case "$url" in
      http://*|https://*)
        base=$(basename "$url")
        ;;
      /*)
        base=$(basename "$url")
        ;;
      *)
        base=$(basename "$url")
        ;;
    esac
    [ -n "$name" ] && base="$name"

    cached="$ADM_SRC_CACHE/$base"

    fetch_one() {
      if printf '%s' "$url" | "$ADM_GREP" -qE '^(https?://)'; then
        log "fetch: $url -> $cached"
        # shellcheck disable=SC2086
        $fetchcmd "$cached.tmp" "$url" || return 1
        mv "$cached.tmp" "$cached" || return 1
      else
        # local path relative to PKGDIR
        if [ -f "$PKGDIR/$url" ]; then
          log "copy local source: $PKGDIR/$url -> $cached"
          "$ADM_CP" -f "$PKGDIR/$url" "$cached" || return 1
        elif [ -f "$url" ]; then
          log "copy local source: $url -> $cached"
          "$ADM_CP" -f "$url" "$cached" || return 1
        else
          die "source not found: $url"
        fi
      fi
      return 0
    }

    if [ -f "$cached" ]; then
      got="$(checksum_file "$SUMTYPE" "$cached" || true)"
      if [ "$got" != "$exp" ]; then
        log "checksum mismatch for cached $base; deleting and refetching"
        "$ADM_RM" -f "$cached"
      fi
    fi

    if [ ! -f "$cached" ]; then
      fetch_one || die "failed to fetch source: $url"
      got="$(checksum_file "$SUMTYPE" "$cached")"
      [ "$got" = "$exp" ] || { "$ADM_RM" -f "$cached"; die "checksum mismatch after download: $base"; }
    fi

    # Copy into workdir for build
    "$ADM_CP" -f "$cached" "$WORKDIR/$base" || die "cannot stage source: $base"
    i=$((i+1))
  done
}

###############################################################################
# Patch + files overlay
###############################################################################
apply_patches() {
  patchdir="$PKGDIR/patch"
  [ -d "$patchdir" ] || return 0
  need_cmd patch

  # Apply patches in sorted order
  "$ADM_FIND" "$patchdir" -type f 2>/dev/null | "$ADM_SORT" | while IFS= read -r p; do
    log "apply patch: $(basename "$p")"
    # Default: patch from WORKSRC (set later). If not, patch from WORKDIR.
    if [ -n "${WORKSRC:-}" ] && [ -d "$WORKSRC" ]; then
      (cd "$WORKSRC" && patch -p1 <"$p") || die "patch failed: $p"
    else
      (cd "$WORKDIR" && patch -p1 <"$p") || die "patch failed: $p"
    fi
  done
}

copy_files_overlay() {
  filesdir="$PKGDIR/files"
  [ -d "$filesdir" ] || return 0
  log "overlay files/: copying into DESTDIR"
  (cd "$filesdir" && "$ADM_TAR" -cf - .) | (cd "$DESTDIR" && "$ADM_TAR" -xf -) || die "files/ overlay failed"
}

###############################################################################
# Dependency parsing + topological sort with cycle detection
###############################################################################
normalize_dep_list() {
  # input: string of deps separated by spaces/newlines
  # output: one per line, stripped, unique
  printf '%s\n' "$1" | "$ADM_SED" 's/[[:space:]]\+/ /g' | "$ADM_SED" 's/^ *//; s/ *$//' \
    | "$ADM_TR" ' ' '\n' 2>/dev/null || true
}

dep_edges_for_pkg() {
  # args: pkgname
  pd="$(pkg_path_from_name "$1" || true)"
  [ -n "$pd" ] || die "cannot locate package: $1"
  load_build_script "$pd"
  # Only runtime deps for ordering; include build deps too for build correctness
  all_deps=$(printf '%s\n%s\n' "$DEPENDS" "$BUILD_DEPENDS" | "$ADM_SED" '/^[[:space:]]*$/d')
  printf '%s\n' "$all_deps" | "$ADM_SED" 's/[[:space:]]\+/ /g' | "$ADM_SED" 's/^ *//; s/ *$//' | "$ADM_TR" ' ' '\n' 2>/dev/null \
    | "$ADM_SED" '/^[[:space:]]*$/d' | while IFS= read -r d; do
      # format: A B means A depends on B
      printf '%s %s\n' "$1" "$d"
    done
}

toposort() {
  # Input: list of package names (one per line) in $1 file.
  # Output: ordered list on stdout, or die on cycle.
  inlist="$1"
  tmp="$WORKDIR/.topo"
  edges="$tmp.edges"
  nodes="$tmp.nodes"
  indeg="$tmp.indeg"
  queue="$tmp.queue"
  out="$tmp.out"

  : >"$edges"; : >"$nodes"; : >"$indeg"; : >"$queue"; : >"$out"

  # Collect closure of dependencies
  # BFS over packages, emitting nodes and edges
  seen="$tmp.seen"
  : >"$seen"
  frontier="$tmp.frontier"
  "$ADM_CP" -f "$inlist" "$frontier"

  while :; do
    # remove empties and duplicates
    "$ADM_SED" '/^[[:space:]]*$/d' "$frontier" | "$ADM_SORT" -u >"$frontier.u"
    mv "$frontier.u" "$frontier"

    [ -s "$frontier" ] || break

    : >"$tmp.next"
    while IFS= read -r p; do
      "$ADM_GREP" -qx "$p" "$seen" 2>/dev/null && continue
      printf '%s\n' "$p" >>"$seen"
      printf '%s\n' "$p" >>"$nodes"

      dep_edges_for_pkg "$p" >>"$edges"
      # enqueue deps to explore
      dep_edges_for_pkg "$p" | "$ADM_AWK" '{print $2}' >>"$tmp.next"
    done <"$frontier"

    mv "$tmp.next" "$frontier"
  done

  # Unique nodes
  "$ADM_SORT" -u "$nodes" >"$nodes.u" && mv "$nodes.u" "$nodes"

  # Compute indegree for each node
  while IFS= read -r n; do
    c=$("$ADM_GREP" -E "^[^ ]+ $n$" "$edges" 2>/dev/null | "$ADM_AWK" 'END{print NR+0}')
    printf '%s %s\n' "$n" "$c" >>"$indeg"
  done <"$nodes"

  # Initialize queue with indegree 0
  "$ADM_AWK" '$2==0{print $1}' "$indeg" >"$queue"

  # Kahn's algorithm
  processed=0
  total=$("$ADM_AWK" 'END{print NR+0}' "$nodes")

  while [ -s "$queue" ]; do
    # pop first
    n=$("$ADM_AWK" 'NR==1{print $1; exit}' "$queue")
    "$ADM_AWK" 'NR>1{print}' "$queue" >"$queue.tmp" && mv "$queue.tmp" "$queue"
    printf '%s\n' "$n" >>"$out"
    processed=$((processed+1))

    # For each m where n->m (meaning m depends on n?) our edges are A depends on B (A->B)
    # In Kahn we need adjacency from B to A to decrement indegree(A) when B processed.
    # So: find all A such that A depends on n.
    "$ADM_GREP" -E "^[^ ]+ $n$" "$edges" 2>/dev/null | "$ADM_AWK" '{print $1}' | while IFS= read -r a; do
      # decrement indegree of a
      cur=$("$ADM_AWK" -v k="$a" '$1==k{print $2; exit}' "$indeg")
      new=$((cur-1))
      "$ADM_AWK" -v k="$a" -v v="$new" '{if($1==k){print $1, v}else{print}}' "$indeg" >"$indeg.tmp" && mv "$indeg.tmp" "$indeg"
      if [ "$new" -eq 0 ]; then
        printf '%s\n' "$a" >>"$queue"
      fi
    done
  done

  if [ "$processed" -ne "$total" ]; then
    # Cycle exists: report remaining nodes with indegree > 0
    log "dependency cycle detected. Remaining nodes:"
    "$ADM_AWK" '$2>0{print " - "$1}' "$indeg" >&2
    die "cannot resolve dependency order due to cycle"
  fi

  # Output build order should build deps first:
  # Our out contains deps later? With our decrement logic, it outputs deps first then dependents -> correct.
  cat "$out"
}

###############################################################################
# Packaging, install, uninstall, upgrade
###############################################################################
pkg_artifact_path() {
  # Prefer zst then xz; store by pkgid
  echo "$ADM_BIN_CACHE/$(pkg_id).tar.zst"
}

pkg_artifact_path_xz() {
  echo "$ADM_BIN_CACHE/$(pkg_id).tar.xz"
}

write_meta() {
  ensure_dir "$(db_pkg_dir)"
  {
    echo "PKGNAME=$PKGNAME"
    echo "PKGVER=$PKGVER"
    echo "PKGREL=$PKGREL"
    echo "SECTION=$SECTION"
    echo "PKGDESC=$PKGDESC"
    echo "PKGURL=$PKGURL"
    echo "LICENSE=$LICENSE"
    echo "ARCH=$ARCH"
    echo "DEPENDS=$(printf '%s' "$DEPENDS" | "$ADM_SED" 's/[[:space:]]\+/ /g' | "$ADM_SED" 's/^ *//; s/ *$//')"
    echo "BUILD_DEPENDS=$(printf '%s' "$BUILD_DEPENDS" | "$ADM_SED" 's/[[:space:]]\+/ /g' | "$ADM_SED" 's/^ *//; s/ *$//')"
    echo "BUILDTIME=$(now)"
  } >"$(db_meta)"
}

make_manifest() {
  # manifest: all installed paths (relative to /)
  # run from DESTDIR root
  (cd "$DESTDIR" && "$ADM_FIND" . -mindepth 1 -print | "$ADM_SED" 's#^\./##') | "$ADM_SORT" >"$WORKDIR/manifest"
}

strip_binaries() {
  [ "${ADM_STRIP:-1}" -eq 1 ] || return 0
  command -v strip >/dev/null 2>&1 || return 0
  # Strip common executable/shared objects
  (cd "$DESTDIR" && "$ADM_FIND" . -type f 2>/dev/null) | while IFS= read -r f; do
    case "$f" in
      */bin/*|*/sbin/*|*/lib/*.so*|*/libexec/*)
        strip --strip-unneeded "$DESTDIR/$f" 2>/dev/null || true
        ;;
    esac
  done
}

pack_destdir() {
  ensure_dir "$ADM_BIN_CACHE"
  zst="$(pkg_artifact_path)"
  xz="$(pkg_artifact_path_xz)"

  make_manifest
  strip_binaries

  # pack as tar from DESTDIR root
  if command -v "$ADM_ZSTD" >/dev/null 2>&1; then
    log "pack: creating $(basename "$zst")"
    (cd "$DESTDIR" && "$ADM_TAR" -cf - .) | "$ADM_ZSTD" -q -T0 -19 -o "$zst.tmp" || die "zstd packaging failed"
    mv "$zst.tmp" "$zst" || die "cannot move artifact"
    [ -f "$xz" ] && "$ADM_RM" -f "$xz" || true
  else
    need_cmd "$ADM_XZ"
    log "pack: creating $(basename "$xz") (fallback)"
    (cd "$DESTDIR" && "$ADM_TAR" -cf - .) | "$ADM_XZ" -c -T0 -9 >"$xz.tmp" || die "xz packaging failed"
    mv "$xz.tmp" "$xz" || die "cannot move artifact"
    [ -f "$zst" ] && "$ADM_RM" -f "$zst" || true
  fi
}

extract_artifact_to_root() {
  # args: artifact path
  a="$1"
  [ -f "$a" ] || die "artifact not found: $a"
  log "install: extracting $(basename "$a") to $ADM_ROOT"
  case "$a" in
    *.tar.zst)
      need_cmd "$ADM_ZSTD"
      # shellcheck disable=SC2086
      "$ADM_ZSTD" -dc "$a" | (cd "$ADM_ROOT" && "$ADM_TAR" -xpf -) || die "extract failed"
      ;;
    *.tar.xz)
      need_cmd "$ADM_XZ"
      "$ADM_XZ" -dc "$a" | (cd "$ADM_ROOT" && "$ADM_TAR" -xpf -) || die "extract failed"
      ;;
    *) die "unknown artifact type: $a" ;;
  esac
}

remove_paths_from_manifest() {
  # args: manifest file
  mf="$1"
  [ -f "$mf" ] || return 0
  # remove files first, then prune empty dirs
  log "uninstall: removing files"
  while IFS= read -r p; do
    [ -n "$p" ] || continue
    # prevent unsafe deletions
    case "$p" in
      ""|"/"|".") continue ;;
    esac
    if [ -f "$ADM_ROOT/$p" ] || [ -L "$ADM_ROOT/$p" ]; then
      "$ADM_RM" -f "$ADM_ROOT/$p" 2>/dev/null || true
    fi
  done <"$mf"

  log "uninstall: pruning empty directories"
  # reverse sort by depth
  "$ADM_AWK" -F/ '{print NF, $0}' "$mf" | "$ADM_SORT" -rn | "$ADM_AWK" '{ $1=""; sub(/^ /,""); print }' \
    | while IFS= read -r p; do
      [ -d "$ADM_ROOT/$p" ] && rmdir "$ADM_ROOT/$p" 2>/dev/null || true
    done
}

mark_installed() {
  ensure_dir "$(db_pkg_dir)"
  "$ADM_TOUCH" "$(db_installed_marker)"
  mv "$WORKDIR/manifest" "$(db_manifest)" || die "cannot store manifest"
  write_meta
}

###############################################################################
# Hooks and default phases
###############################################################################
run_hook() {
  # args: hookname
  h="$1"
  # Build scripts may define: hook_pre_fetch, hook_post_fetch, etc.
  fn="hook_$h"
  if command -v "$fn" >/dev/null 2>&1; then
    log "hook: $fn"
    "$fn" || die "hook failed: $fn"
  fi
}

default_unpack() {
  # Heuristic: if there is exactly one tar.* among staged sources, unpack it.
  # Build scripts can override by defining pkg_unpack()
  tarball=$("$ADM_FIND" "$WORKDIR" -maxdepth 1 -type f 2>/dev/null | "$ADM_GREP" -E '\.(tar\.gz|tar\.bz2|tar\.xz|tar\.zst|tgz|tbz2|txz|tar)$' | "$ADM_SORT" | "$ADM_AWK" 'NR==1{print; exit}')
  [ -n "$tarball" ] || return 0

  log "unpack: $(basename "$tarball")"
  # Prepare WORKSRC directory
  WORKSRC="$WORKDIR/src"
  ensure_dir "$WORKSRC"
  case "$tarball" in
    *.tar.zst)
      need_cmd "$ADM_ZSTD"
      "$ADM_ZSTD" -dc "$tarball" | (cd "$WORKSRC" && "$ADM_TAR" -xpf -) || die "unpack failed"
      ;;
    *.tar.xz|*.txz)
      need_cmd "$ADM_XZ"
      "$ADM_XZ" -dc "$tarball" | (cd "$WORKSRC" && "$ADM_TAR" -xpf -) || die "unpack failed"
      ;;
    *.tar.gz|*.tgz)
      need_cmd gzip
      gzip -dc "$tarball" | (cd "$WORKSRC" && "$ADM_TAR" -xpf -) || die "unpack failed"
      ;;
    *.tar.bz2|*.tbz2)
      need_cmd bzip2
      bzip2 -dc "$tarball" | (cd "$WORKSRC" && "$ADM_TAR" -xpf -) || die "unpack failed"
      ;;
    *.tar)
      (cd "$WORKSRC" && "$ADM_TAR" -xpf "$tarball") || die "unpack failed"
      ;;
    *) return 0 ;;
  esac

  # If tar produced a single top-level dir, use it
  top=$("$ADM_FIND" "$WORKSRC" -mindepth 1 -maxdepth 1 -type d 2>/dev/null | "$ADM_SORT" | "$ADM_AWK" 'NR==1{print; exit}')
  if [ -n "$top" ]; then
    WORKSRC="$top"
  fi
  export WORKSRC
}

default_prepare() {
  # Apply patches after unpack by default
  apply_patches
}

have() { command -v "$1" >/dev/null 2>&1; }

pick_ninja() { have ninja && echo ninja && return 0; have samu && echo samu && return 0; echo ""; }

# Decide o diretório de trabalho do source (WORKSRC se existe, senão WORKDIR)
srcdir() {
  if [ -n "${WORKSRC:-}" ] && [ -d "$WORKSRC" ]; then
    echo "$WORKSRC"
  else
    echo "$WORKDIR"
  fi
}

detect_build_system() {
  d="$(srcdir)"

  # Rust
  if [ -f "$d/Cargo.toml" ]; then echo "cargo"; return 0; fi
  # Go (módulo ou GOPATH legacy)
  if [ -f "$d/go.mod" ] || [ -f "$d/Gopkg.lock" ] || [ -n "$(ls "$d"/*.go 2>/dev/null | "$ADM_AWK" 'NR==1{print}')" ]; then
    echo "go"; return 0
  fi
  # Meson
  if [ -f "$d/meson.build" ]; then echo "meson"; return 0; fi
  # CMake
  if [ -f "$d/CMakeLists.txt" ]; then echo "cmake"; return 0; fi
  # Autotools (configure)
  if [ -x "$d/configure" ]; then echo "autotools"; return 0; fi
  # Autotools (configure.ac / Makefile.am) -> precisa autoreconf
  if [ -f "$d/configure.ac" ] || [ -f "$d/configure.in" ] || [ -f "$d/Makefile.am" ]; then
    echo "autotools_bootstrap"; return 0
  fi
  # Make puro
  if [ -f "$d/Makefile" ] || [ -f "$d/makefile" ] || [ -f "$d/GNUmakefile" ]; then echo "make"; return 0; fi

  echo "unknown"
}

default_build() {
  d="$(srcdir)"
  cd "$d" || die "cannot cd source dir: $d"

  export CC="${CC:-cc}"
  export CXX="${CXX:-c++}"
  export CFLAGS="${CFLAGS:-$ADM_CFLAGS}"
  export CXXFLAGS="${CXXFLAGS:-$ADM_CXXFLAGS}"
  export LDFLAGS="${LDFLAGS:-$ADM_LDFLAGS}"
  export MAKEFLAGS="${MAKEFLAGS:-$ADM_MAKEFLAGS}"

  sys="$(detect_build_system)"
  log "autodetect build system: $sys"

  case "$sys" in
    cargo)
      have cargo || die "cargo not found (add rust/cargo to BUILD_DEPENDS)"
      # padrão robusto: build release
      log "build: cargo build --release"
      cargo build --release || die "cargo build failed"
      ;;

    go)
      have go || die "go not found (add go to BUILD_DEPENDS)"
      # go não tem padrão universal de install para /usr; regra:
      # - se existir Makefile, use make (já teria caído em make)
      # - senão: build binário principal para ./build-out (se tiver cmd/)
      out="$WORKDIR/.go-out"
      ensure_dir "$out"
      log "build: go build"
      if [ -d "$d/cmd" ]; then
        # constrói cada cmd como binário separado (comum em projetos Go)
        for c in "$d"/cmd/*; do
          [ -d "$c" ] || continue
          name=$(basename "$c")
          (cd "$c" && go build -trimpath -ldflags="-s -w" -o "$out/$name") || die "go build failed for cmd/$name"
        done
      else
        # single-module
        go build -trimpath -ldflags="-s -w" -o "$out/$PKGNAME" ./... 2>/dev/null || \
          go build -trimpath -ldflags="-s -w" -o "$out/$PKGNAME" . || die "go build failed"
      fi
      ;;

    meson)
      have meson || die "meson not found (add meson to BUILD_DEPENDS)"
      n="$(pick_ninja)"
      [ -n "$n" ] || die "need ninja or samu for meson projects"
      b="$WORKDIR/.build-meson"
      ensure_dir "$b"
      log "build: meson setup"
      # --prefix=/usr e DESTDIR no install depois
      (cd "$b" && meson setup "$d" --prefix=/usr --buildtype=release) || die "meson setup failed"
      log "build: meson compile"
      (cd "$b" && meson compile -j "$ADM_JOBS") || die "meson compile failed"
      ;;

    cmake)
      have cmake || die "cmake not found (add cmake to BUILD_DEPENDS)"
      n="$(pick_ninja)"
      b="$WORKDIR/.build-cmake"
      ensure_dir "$b"
      gen="Unix Makefiles"
      if [ -n "$n" ]; then gen="Ninja"; fi
      log "build: cmake configure ($gen)"
      (cd "$b" && cmake -G "$gen" -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_BUILD_TYPE=Release "$d") || die "cmake configure failed"
      log "build: cmake build"
      (cd "$b" && cmake --build . -- -j "$ADM_JOBS") || die "cmake build failed"
      ;;

    autotools_bootstrap)
      have autoreconf || die "autoreconf not found (add autoconf/automake/libtool to BUILD_DEPENDS)"
      log "build: autoreconf -fi"
      autoreconf -fi || die "autoreconf failed"
      # cai no autotools normal
      log "build: ./configure"
      ./configure --prefix=/usr --sysconfdir=/etc --localstatedir=/var || die "configure failed"
      log "build: make"
      make -j"$ADM_JOBS" || die "make failed"
      ;;

    autotools)
      log "build: ./configure"
      ./configure --prefix=/usr --sysconfdir=/etc --localstatedir=/var || die "configure failed"
      log "build: make"
      make -j"$ADM_JOBS" || die "make failed"
      ;;

    make)
      log "build: make"
      make -j"$ADM_JOBS" || die "make failed"
      ;;

    *)
      die "unknown build system; define pkg_build/pkg_install in build script for this package"
      ;;
  esac
}

default_check() { :; }

default_install() {
  d="$(srcdir)"
  sys="$(detect_build_system)"
  log "autodetect install system: $sys"

  case "$sys" in
    cargo)
      # Cargo não tem install padrão para /usr com DESTDIR universal.
      # Estratégia: instalar binários de target/release em /usr/bin (se houver).
      # (Para crates library-only, não instala nada.)
      bindir="$DESTDIR/usr/bin"
      ensure_dir "$bindir"
      # binários: heurística: se existir target/release/* executável
      # Instala apenas executáveis regulares.
      td="$d/target/release"
      [ -d "$td" ] || die "cargo target/release not found"
      log "install: cargo binaries -> /usr/bin"
      for f in "$td"/*; do
        [ -f "$f" ] || continue
        [ -x "$f" ] || continue
        case "$(basename "$f")" in
          *.d|*.rlib|*.so|*.a) continue ;;
        esac
        "$ADM_INSTALL" -m 0755 "$f" "$bindir/$(basename "$f")" || die "install failed: $(basename "$f")"
      done
      ;;

    go)
      bindir="$DESTDIR/usr/bin"
      ensure_dir "$bindir"
      out="$WORKDIR/.go-out"
      [ -d "$out" ] || die "go build output not found"
      log "install: go binaries -> /usr/bin"
      for f in "$out"/*; do
        [ -f "$f" ] || continue
        "$ADM_INSTALL" -m 0755 "$f" "$bindir/$(basename "$f")" || die "install failed: $(basename "$f")"
      done
      ;;

    meson)
      b="$WORKDIR/.build-meson"
      [ -d "$b" ] || die "meson build dir missing"
      log "install: meson install (DESTDIR)"
      (cd "$b" && meson install --destdir "$DESTDIR") || die "meson install failed"
      ;;

    cmake)
      b="$WORKDIR/.build-cmake"
      [ -d "$b" ] || die "cmake build dir missing"
      log "install: cmake install (DESTDIR)"
      (cd "$b" && cmake --install . --prefix /usr --strip --component "") >/dev/null 2>&1 || true
      # cmake --install não usa DESTDIR de forma uniforme; melhor exportar DESTDIR:
      (cd "$b" && DESTDIR="$DESTDIR" cmake --install .) || die "cmake install failed"
      ;;

    autotools_bootstrap|autotools|make)
      cd "$d" || die "cannot cd source dir: $d"
      log "install: make DESTDIR=... install"
      make DESTDIR="$DESTDIR" install || die "make install failed"
      ;;

    *)
      die "unknown install system; define pkg_install in build script"
      ;;
  esac
}

call_phase() {
  # args: phase
  ph="$1"
  fn="pkg_$ph"
  run_hook "pre_$ph"
  if command -v "$fn" >/dev/null 2>&1; then
    log "phase: $fn"
    "$fn" || die "phase failed: $fn"
  else
    case "$ph" in
      unpack) default_unpack ;;
      prepare) default_prepare ;;
      build) default_build ;;
      check) default_check ;;
      install) default_install ;;
      *) die "unknown phase: $ph" ;;
    esac
  fi
  run_hook "post_$ph"
}

###############################################################################
# Resume and clean build dirs
###############################################################################
state_file() { echo "$WORKDIR/.state"; }

state_set() { echo "$1" >"$(state_file)"; }

state_get() {
  [ -f "$(state_file)" ] && cat "$(state_file)" || echo "none"
}

clean_workdir() {
  [ -n "${WORKDIR:-}" ] && [ -d "$WORKDIR" ] && "$ADM_RM" -rf "$WORKDIR" || true
}

prepare_workdir() {
  ensure_dir "$ADM_BUILD_DIR"
  WORKDIR="$ADM_BUILD_DIR/$PKGNAME-$PKGVER-r$PKGREL"
  DESTDIR="$WORKDIR/destdir"
  ensure_dir "$WORKDIR"
  # Always clean DESTDIR before build (no bloat / deterministic)
  [ -d "$DESTDIR" ] && "$ADM_RM" -rf "$DESTDIR"
  ensure_dir "$DESTDIR"
  export WORKDIR DESTDIR
}

###############################################################################
# Build from scripts and create binary package
###############################################################################
build_pkg() {
  # args: pkgdir
  load_build_script "$1"
  log_init

  ADM_CURRENT_LOG="$(log_file_for "$PKGNAME" "$PKGVER" "$PKGREL")"
  export ADM_CURRENT_LOG
  ensure_dir "$(dirname "$ADM_CURRENT_LOG")"

  log "build start: $(pkg_id) (section=$SECTION)"
  prepare_workdir

  # resume support: if state exists, continue from next phase
  st="$(state_get)"
  case "$st" in
    none) next="fetch" ;;
    fetch) next="unpack" ;;
    unpack) next="prepare" ;;
    prepare) next="build" ;;
    build) next="check" ;;
    check) next="install" ;;
    install) next="package" ;;
    package) next="done" ;;
    done) next="done" ;;
    *) next="fetch" ;;
  esac

  # Fetch always safe to re-run; but honor resume by skipping if already marked
  if [ "$st" = "none" ] || [ "$st" = "fetch" ]; then
    state_set "fetch"
    call_phase "fetch" 2>/dev/null || true
    # If pkg_fetch not defined, use default verify_sources fetch
    if ! command -v pkg_fetch >/dev/null 2>&1; then
      verify_sources
    fi
    state_set "unpack"
  fi

  if [ "$next" = "unpack" ] || [ "$st" = "unpack" ]; then
    state_set "unpack"
    call_phase "unpack"
    state_set "prepare"
  fi

  if [ "$next" = "prepare" ] || [ "$st" = "prepare" ]; then
    state_set "prepare"
    call_phase "prepare"
    state_set "build"
  fi

  if [ "$next" = "build" ] || [ "$st" = "build" ]; then
    state_set "build"
    call_phase "build"
    state_set "check"
  fi

  if [ "$next" = "check" ] || [ "$st" = "check" ]; then
    state_set "check"
    call_phase "check"
    state_set "install"
  fi

  if [ "$next" = "install" ] || [ "$st" = "install" ]; then
    state_set "install"
    call_phase "install"
    copy_files_overlay
    state_set "package"
  fi

  if [ "$next" = "package" ] || [ "$st" = "package" ]; then
    state_set "package"
    pack_destdir
    state_set "done"
  fi

  log "build done: $(pkg_id)"
}

###############################################################################
# Install flow: from cache if available, else build then install.
###############################################################################
artifact_for_loaded_pkg() {
  z="$(pkg_artifact_path)"
  x="$(pkg_artifact_path_xz)"
  if [ -f "$z" ]; then echo "$z"; return 0; fi
  if [ -f "$x" ]; then echo "$x"; return 0; fi
  return 1
}

install_pkg_loaded() {
  # Requires load_build_script already done
  a="$(artifact_for_loaded_pkg || true)"
  if [ -z "$a" ]; then
    # build it
    build_pkg "$PKGDIR"
    a="$(artifact_for_loaded_pkg)" || die "build completed but no artifact found"
  fi

  # atomic upgrade: extract to a staging dir first, then apply, then remove old only after success
  staging="$ADM_BUILD_DIR/.stage-$PKGNAME-$$"
  ensure_dir "$staging"
  log "install: staging extract to $staging"
  case "$a" in
    *.tar.zst)
      need_cmd "$ADM_ZSTD"
      "$ADM_ZSTD" -dc "$a" | (cd "$staging" && "$ADM_TAR" -xpf -) || die "staging extract failed"
      ;;
    *.tar.xz)
      need_cmd "$ADM_XZ"
      "$ADM_XZ" -dc "$a" | (cd "$staging" && "$ADM_TAR" -xpf -) || die "staging extract failed"
      ;;
  esac

  # If installed, keep old manifest for uninstall after success
  oldmf="$(db_manifest)"
  oldmf_tmp=""
  if is_installed; then
    oldmf_tmp="$ADM_BUILD_DIR/.oldmf-$PKGNAME-$$"
    [ -f "$oldmf" ] && "$ADM_CP" -f "$oldmf" "$oldmf_tmp" || true
  fi

  # Apply staging to root
  log "install: applying to root $ADM_ROOT"
  (cd "$staging" && "$ADM_TAR" -cf - .) | (cd "$ADM_ROOT" && "$ADM_TAR" -xpf -) || die "apply failed"

  # Create new manifest from staging
  ensure_dir "$(db_pkg_dir)"
  (cd "$staging" && "$ADM_FIND" . -mindepth 1 -print | "$ADM_SED" 's#^\./##') | "$ADM_SORT" >"$ADM_BUILD_DIR/.newmf-$PKGNAME-$$"

  # Commit DB first
  mv "$ADM_BUILD_DIR/.newmf-$PKGNAME-$$" "$(db_manifest)" || die "cannot commit manifest"
  "$ADM_TOUCH" "$(db_installed_marker)"
  write_meta

  # Only now remove old files that are not part of new manifest
  if [ -n "$oldmf_tmp" ] && [ -f "$oldmf_tmp" ]; then
    log "upgrade: removing old files not present in new manifest"
    "$ADM_GREP" -vxFf "$(db_manifest)" "$oldmf_tmp" >"$ADM_BUILD_DIR/.remove-$PKGNAME-$$" || true
    remove_paths_from_manifest "$ADM_BUILD_DIR/.remove-$PKGNAME-$$"
    "$ADM_RM" -f "$ADM_BUILD_DIR/.remove-$PKGNAME-$$" "$oldmf_tmp" || true
  fi

  "$ADM_RM" -rf "$staging" || true
  log "installed: $(pkg_id)"
}

###############################################################################
# High-level operations
###############################################################################
install_with_deps() {
  # args: pkgname or category/name
  target="$1"
  pd="$(pkg_path_from_name "$target")" || die "package not found: $target"
  load_build_script "$pd"

  # Resolve dependency order (closure) and install in order
  req="$WORKDIR/.req"
  ensure_dir "$ADM_BUILD_DIR"
  WORKDIR="$ADM_BUILD_DIR/.op-$$"
  ensure_dir "$WORKDIR"
  echo "$PKGNAME" >"$req"

  order="$(toposort "$req")" || die "dependency resolution failed"
  printf '%s\n' "$order" | while IFS= read -r p; do
    pdir="$(pkg_path_from_name "$p")" || die "missing build script for dependency: $p"
    load_build_script "$pdir"
    if is_installed; then
      log "dep already installed: $p"
    else
      log "installing dep: $p"
      install_pkg_loaded
    fi
  done

  "$ADM_RM" -rf "$WORKDIR" || true
}

uninstall_pkg() {
  # args: pkgname
  n="$1"
  pdir="$(db_pkg_dir)/manifest"
  [ -f "$pdir" ] || die "not installed: $n"
  log_init
  log "uninstall: $n"
  remove_paths_from_manifest "$pdir"
  "$ADM_RM" -rf "$(db_pkg_dir)" || true
  log "uninstalled: $n"
}

info_pkg() {
  # args: pkgname or category/name
  target="$1"
  pd="$(pkg_path_from_name "$target" 2>/dev/null || true)"
  if [ -n "$pd" ]; then
    load_build_script "$pd"
    installed="no"
    is_installed && installed="yes"
    if [ "$installed" = "yes" ]; then mark="[ ✔️ ]"; else mark="[     ]"; fi
    echo "$mark $PKGNAME"
    echo "  Version: $PKGVER-r$PKGREL"
    echo "  Section: $SECTION"
    echo "  Desc:    ${PKGDESC:-}"
    echo "  URL:     ${PKGURL:-}"
    echo "  License: ${LICENSE:-}"
    echo "  Arch:    ${ARCH:-}"
    echo "  Depends: $(printf '%s' "$DEPENDS" | "$ADM_SED" 's/[[:space:]]\+/ /g' | "$ADM_SED" 's/^ *//; s/ *$//')"
    echo "  BDepends: $(printf '%s' "$BUILD_DEPENDS" | "$ADM_SED" 's/[[:space:]]\+/ /g' | "$ADM_SED" 's/^ *//; s/ *$//')"
  else
    # maybe installed but build script missing
    d="$ADM_DB_DIR/pkgs/$target/meta"
    if [ -f "$d" ]; then
      echo "[ ✔️ ] $target (installed; build script missing)"
      cat "$d" | "$ADM_SED" 's/^/  /'
    else
      die "package not found: $target"
    fi
  fi
}

search_pkgs() {
  # args: pattern
  pat="$1"
  [ -n "$pat" ] || pat="."
  "$ADM_FIND" "$ADM_PKGS_DIR" -mindepth 2 -maxdepth 2 -type f -name build 2>/dev/null | while IFS= read -r b; do
    d=$(dirname "$b")
    c=$(basename "$(dirname "$d")")
    n=$(basename "$d")
    case "$n" in
      *"$pat"*) ;;
      *) continue ;;
    esac
    p="$c/$n"
    # installed mark
    if [ -f "$ADM_DB_DIR/pkgs/$n/installed" ]; then
      echo "[ ✔️ ] $p"
    else
      echo "[     ] $p"
    fi
  done | "$ADM_SORT"
}

list_installed() {
  ensure_dir "$ADM_DB_DIR/pkgs"
  "$ADM_FIND" "$ADM_DB_DIR/pkgs" -mindepth 2 -maxdepth 2 -type f -name installed 2>/dev/null | while IFS= read -r f; do
    n=$(basename "$(dirname "$f")")
    echo "[ ✔️ ] $n"
  done | "$ADM_SORT"
}

sync_git() {
  # optional: commit and push changes in ADM_GIT_REPO_DIR
  [ -d "$ADM_GIT_REPO_DIR/.git" ] || die "not a git repo: $ADM_GIT_REPO_DIR"
  need_cmd "$ADM_GIT"
  (cd "$ADM_GIT_REPO_DIR" && \
    "$ADM_GIT" add -A && \
    "$ADM_GIT" status --porcelain | "$ADM_GREP" -q . || { msg "nothing to commit"; exit 0; } && \
    "$ADM_GIT" commit -m "adm-pkg sync $(now)" && \
    "$ADM_GIT" push) || die "git sync failed"
  msg "git sync complete"
}

clean_system() {
  log_init
  msg "clean: removing leftover build dirs older than 7 days"
  # Busybox find may lack -mtime; try anyway.
  "$ADM_FIND" "$ADM_BUILD_DIR" -mindepth 1 -maxdepth 1 -type d -mtime +7 2>/dev/null | while IFS= read -r d; do
    "$ADM_RM" -rf "$d" 2>/dev/null || true
  done
  msg "clean: done"
}

rebuild_pkg() {
  # args: pkgname
  target="$1"
  pd="$(pkg_path_from_name "$target")" || die "package not found: $target"
  load_build_script "$pd"
  # wipe existing workdir state to force clean rebuild
  ensure_dir "$ADM_BUILD_DIR"
  w="$ADM_BUILD_DIR/$PKGNAME-$PKGVER-r$PKGREL"
  [ -d "$w" ] && "$ADM_RM" -rf "$w" || true
  build_pkg "$pd"
  install_pkg_loaded
}

rebuild_world() {
  # Rebuild all installed packages in dependency order (best-effort).
  log_init
  ensure_dir "$ADM_BUILD_DIR"
  WORKDIR="$ADM_BUILD_DIR/.world-$$"
  ensure_dir "$WORKDIR"

  # collect installed names
  inst="$WORKDIR/installed"
  : >"$inst"
  "$ADM_FIND" "$ADM_DB_DIR/pkgs" -mindepth 2 -maxdepth 2 -type f -name installed 2>/dev/null \
    | while IFS= read -r f; do basename "$(dirname "$f")"; done | "$ADM_SORT" -u >"$inst"

  [ -s "$inst" ] || die "no installed packages to rebuild"

  order="$(toposort "$inst")" || die "dependency resolution failed for world rebuild"
  printf '%s\n' "$order" | while IFS= read -r p; do
    # Only rebuild if installed
    [ -f "$ADM_DB_DIR/pkgs/$p/installed" ] || continue
    msg "rebuild: $p"
    rebuild_pkg "$p"
  done

  "$ADM_RM" -rf "$WORKDIR" || true
}

###############################################################################
# CLI
###############################################################################
usage() {
  cat <<EOF
adm-pkg (POSIX sh) - rolling package manager

Usage:
  adm-pkg search <pattern>
  adm-pkg info <pkg|category/pkg>
  adm-pkg list
  adm-pkg install <pkg|category/pkg>
  adm-pkg uninstall <pkg>
  adm-pkg rebuild <pkg|category/pkg>
  adm-pkg rebuild-world
  adm-pkg clean
  adm-pkg sync

Notes:
  - Build scripts live under: $ADM_PKGS_DIR/<category>/<pkg>/build
  - patches: <pkg>/patch/* (auto-applied)
  - files overlay: <pkg>/files/* (copied into DESTDIR)
EOF
}

main() {
  log_init

  cmd="${1:-}"
  case "$cmd" in
    search) shift; search_pkgs "${1:-.}" ;;
    info) shift; [ -n "${1:-}" ] || die "info requires package"; info_pkg "$1" ;;
    list) list_installed ;;
    install) shift; [ -n "${1:-}" ] || die "install requires package"; with_lock; install_with_deps "$1"; unlock ;;
    uninstall) shift; [ -n "${1:-}" ] || die "uninstall requires package"; with_lock; uninstall_pkg "$1"; unlock ;;
    rebuild) shift; [ -n "${1:-}" ] || die "rebuild requires package"; with_lock; rebuild_pkg "$1"; unlock ;;
    rebuild-world) with_lock; rebuild_world; unlock ;;
    clean) with_lock; clean_system; unlock ;;
    sync) with_lock; sync_git; unlock ;;
    help|-h|--help|"") usage ;;
    *) die "unknown command: $cmd (use: adm-pkg help)" ;;
  esac
}

main "$@"
